{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('mental_disorders_reddit.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "df=df.dropna(how='any')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.7)\n",
            "Requirement already satisfied: click in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: joblib in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk) (0.4.4)\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_lowercase(text):\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "def remove_url(text):\n",
        "    re_url = re.compile('https?://\\S+|www\\.\\S+')\n",
        "    return re_url.sub('', text)\n",
        "\n",
        "exclude = string.punctuation\n",
        "def remove_punc(text):\n",
        "    return text.translate(str.maketrans('', '', exclude))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    new_list = []\n",
        "    words = word_tokenize(text)\n",
        "    stopwrds = stopwords.words('english')\n",
        "    for word in words:\n",
        "        if word not in stopwrds:\n",
        "            new_list.append(word)\n",
        "    return ' '.join(new_list)\n",
        "\n",
        "\n",
        "def perform_stemming(text):\n",
        "    stemmer = PorterStemmer()\n",
        "    new_list = []\n",
        "    words = word_tokenize(text)\n",
        "    for word in words:\n",
        "        new_list.append(stemmer.stem(word))\n",
        "\n",
        "    return \" \".join(new_list)\n",
        "\n",
        "\n",
        "def perform_lemmatize(text):\n",
        "    lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "    new_list = []\n",
        "    words = word_tokenize(text)\n",
        "    for word in words:\n",
        "        new_list.append(lem.lemmatize(word))\n",
        "\n",
        "    return \" \".join(new_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>selftext</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>over_18</th>\n",
              "      <th>subreddit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Life is so pointless without others</td>\n",
              "      <td>Does anyone else think the most important part...</td>\n",
              "      <td>1650356960</td>\n",
              "      <td>False</td>\n",
              "      <td>BPD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cold rage?</td>\n",
              "      <td>Hello fellow friends 😄\\n\\nI'm on the BPD spect...</td>\n",
              "      <td>1650356660</td>\n",
              "      <td>False</td>\n",
              "      <td>BPD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I don’t know who I am</td>\n",
              "      <td>My [F20] bf [M20] told me today (after I said ...</td>\n",
              "      <td>1650355379</td>\n",
              "      <td>False</td>\n",
              "      <td>BPD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HELP! Opinions! Advice!</td>\n",
              "      <td>Okay, I’m about to open up about many things I...</td>\n",
              "      <td>1650353430</td>\n",
              "      <td>False</td>\n",
              "      <td>BPD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>help</td>\n",
              "      <td>[removed]</td>\n",
              "      <td>1650350907</td>\n",
              "      <td>False</td>\n",
              "      <td>BPD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701779</th>\n",
              "      <td>I really need to talk to a therapist..</td>\n",
              "      <td>I can't afford a real session and it's 11 PM. ...</td>\n",
              "      <td>1415332108</td>\n",
              "      <td>False</td>\n",
              "      <td>mentalillness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701781</th>\n",
              "      <td>I have pica</td>\n",
              "      <td>Hello. \\n         I'm taking steps to get rid ...</td>\n",
              "      <td>1414896638</td>\n",
              "      <td>False</td>\n",
              "      <td>mentalillness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701782</th>\n",
              "      <td>Where can you go to get help for someone menta...</td>\n",
              "      <td>Someone (a war veteran) I know is mentally ill...</td>\n",
              "      <td>1396298261</td>\n",
              "      <td>False</td>\n",
              "      <td>mentalillness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701783</th>\n",
              "      <td>I am rooster illusion</td>\n",
              "      <td>AMA</td>\n",
              "      <td>1344639905</td>\n",
              "      <td>False</td>\n",
              "      <td>mentalillness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701786</th>\n",
              "      <td>crazy motherfucker</td>\n",
              "      <td>so i have a lot of random impluses. crazy shit...</td>\n",
              "      <td>1321506737</td>\n",
              "      <td>False</td>\n",
              "      <td>mentalillness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>668054 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    title  \\\n",
              "0                     Life is so pointless without others   \n",
              "1                                              Cold rage?   \n",
              "2                                   I don’t know who I am   \n",
              "3                                 HELP! Opinions! Advice!   \n",
              "4                                                    help   \n",
              "...                                                   ...   \n",
              "701779             I really need to talk to a therapist..   \n",
              "701781                                        I have pica   \n",
              "701782  Where can you go to get help for someone menta...   \n",
              "701783                              I am rooster illusion   \n",
              "701786                                 crazy motherfucker   \n",
              "\n",
              "                                                 selftext  created_utc  \\\n",
              "0       Does anyone else think the most important part...   1650356960   \n",
              "1       Hello fellow friends 😄\\n\\nI'm on the BPD spect...   1650356660   \n",
              "2       My [F20] bf [M20] told me today (after I said ...   1650355379   \n",
              "3       Okay, I’m about to open up about many things I...   1650353430   \n",
              "4                                               [removed]   1650350907   \n",
              "...                                                   ...          ...   \n",
              "701779  I can't afford a real session and it's 11 PM. ...   1415332108   \n",
              "701781  Hello. \\n         I'm taking steps to get rid ...   1414896638   \n",
              "701782  Someone (a war veteran) I know is mentally ill...   1396298261   \n",
              "701783                                                AMA   1344639905   \n",
              "701786  so i have a lot of random impluses. crazy shit...   1321506737   \n",
              "\n",
              "        over_18      subreddit  \n",
              "0         False            BPD  \n",
              "1         False            BPD  \n",
              "2         False            BPD  \n",
              "3         False            BPD  \n",
              "4         False            BPD  \n",
              "...         ...            ...  \n",
              "701779    False  mentalillness  \n",
              "701781    False  mentalillness  \n",
              "701782    False  mentalillness  \n",
              "701783    False  mentalillness  \n",
              "701786    False  mentalillness  \n",
              "\n",
              "[668054 rows x 5 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['selftext']=df['selftext'].apply(remove_url)\n",
        "df['selftext']=df['selftext'].apply(remove_punc)\n",
        "df['selftext']=df['selftext'].apply(convert_lowercase)\n",
        "df['selftext']=df['selftext'].apply(remove_stopwords)\n",
        "\n",
        "\n",
        "df['title']=df['title'].apply(remove_url)\n",
        "df['title']=df['title'].apply(remove_punc)\n",
        "df['title']=df['title'].apply(convert_lowercase)\n",
        "df['title']=df['title'].apply(remove_stopwords)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BPD              233119\n",
              "Anxiety          167032\n",
              "depression       156708\n",
              "bipolar           46666\n",
              "mentalillness     44249\n",
              "schizophrenia     20280\n",
              "Name: subreddit, dtype: int64"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['subreddit'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def category_equalization(data_df,col):# функция для баланса значений категорий в таргет \n",
        "    for value in list(data_df[col].unique()):\n",
        "        \n",
        "        num_rows_to_remove=data_df[col].value_counts()[value]-data_df[col].value_counts()['schizophrenia']#надо поменять на мимнимальное значение в value_counts \n",
        "        \n",
        "        rows_with_value = data_df[data_df[col] == value]\n",
        "\n",
        "        data_df = data_df[~data_df.isin(rows_with_value.head(num_rows_to_remove))]\n",
        "    return data_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_equals=category_equalization(df,\"subreddit\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_equals=df_equals.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BPD              20280\n",
              "bipolar          20280\n",
              "depression       20280\n",
              "Anxiety          20280\n",
              "schizophrenia    20280\n",
              "mentalillness    20280\n",
              "Name: subreddit, dtype: int64"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_equals[\"subreddit\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sample=df_equals.sample(n=10000, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "mentalillness    1732\n",
              "BPD              1688\n",
              "schizophrenia    1676\n",
              "Anxiety          1663\n",
              "bipolar          1627\n",
              "depression       1614\n",
              "Name: subreddit, dtype: int64"
            ]
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_sample[\"subreddit\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
            "{'clf__C': 1.0, 'clf__penalty': 'l2', 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
            "0.574\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "X = df_sample['selftext']\n",
        "y = df_sample[\"subreddit\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "\n",
        "pipe_logreg = Pipeline([\n",
        "           ('vect', TfidfVectorizer()),\n",
        "           ('clf', LogisticRegression()),\n",
        "])\n",
        "parameters = [{\n",
        "    'vect__max_features':[None, 5000, 10000, 50000],\n",
        "     'vect__ngram_range': [(1,1), (1,2), (1,3)],\n",
        "    'clf__penalty': ('l1','l2', 'elasticnet',None),\n",
        "    'clf__C': (100, 10, 1.0, 0.1, 0.01)\n",
        "}]\n",
        "\n",
        "grid_search = GridSearchCV(pipe_logreg, parameters,verbose=5,n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy %s 0.6265614727153189\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Anxiety       0.73      0.75      0.74      4041\n",
            "          BPD       0.75      0.77      0.76      4138\n",
            "      bipolar       0.72      0.51      0.59      4092\n",
            "   depression       0.61      0.50      0.55      4125\n",
            "mentalillness       0.52      0.45      0.48      3972\n",
            "schizophrenia       0.50      0.79      0.61      3968\n",
            "\n",
            "     accuracy                           0.63     24336\n",
            "    macro avg       0.64      0.63      0.62     24336\n",
            " weighted avg       0.64      0.63      0.62     24336\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X = df_equals['selftext']\n",
        "y = df_equals[\"subreddit\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "\n",
        "\n",
        "pipe_log = Pipeline([\n",
        "           ('vect', TfidfVectorizer(max_features= 5000,ngram_range=(1,1))),\n",
        "           ('clf', LogisticRegression(C=1.0,penalty='l2',random_state=42,n_jobs=-1)),\n",
        "])\n",
        "pipe_log.fit(X_train, y_train)\n",
        "y_pred = pipe_log.predict(X_test)\n",
        "predicted_prob = pipe_log.predict_proba(X_test)\n",
        "\n",
        "print('accuracy %s',  accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rate set to 0.099937\n",
            "0:\tlearn: 1.7053651\ttotal: 5.01s\tremaining: 1h 23m 24s\n",
            "1:\tlearn: 1.6437596\ttotal: 9.09s\tremaining: 1h 15m 37s\n",
            "2:\tlearn: 1.6019494\ttotal: 12.7s\tremaining: 1h 10m 12s\n",
            "3:\tlearn: 1.5681468\ttotal: 15.9s\tremaining: 1h 6m 10s\n",
            "4:\tlearn: 1.5399438\ttotal: 19.1s\tremaining: 1h 3m 26s\n",
            "5:\tlearn: 1.5157747\ttotal: 22.7s\tremaining: 1h 2m 39s\n",
            "6:\tlearn: 1.4931626\ttotal: 26.7s\tremaining: 1h 3m 10s\n",
            "7:\tlearn: 1.4746128\ttotal: 30.9s\tremaining: 1h 3m 48s\n",
            "8:\tlearn: 1.4591452\ttotal: 34.8s\tremaining: 1h 3m 49s\n",
            "9:\tlearn: 1.4448951\ttotal: 38.2s\tremaining: 1h 2m 59s\n",
            "10:\tlearn: 1.4321282\ttotal: 41.7s\tremaining: 1h 2m 31s\n",
            "11:\tlearn: 1.4202062\ttotal: 45.2s\tremaining: 1h 2m\n",
            "12:\tlearn: 1.4082612\ttotal: 49.6s\tremaining: 1h 2m 44s\n",
            "13:\tlearn: 1.3987996\ttotal: 53.5s\tremaining: 1h 2m 45s\n",
            "14:\tlearn: 1.3888618\ttotal: 56.6s\tremaining: 1h 1m 58s\n",
            "15:\tlearn: 1.3810731\ttotal: 59.8s\tremaining: 1h 1m 17s\n",
            "16:\tlearn: 1.3721528\ttotal: 1m 2s\tremaining: 1h 30s\n",
            "17:\tlearn: 1.3633906\ttotal: 1m 6s\tremaining: 1h 19s\n",
            "18:\tlearn: 1.3563735\ttotal: 1m 9s\tremaining: 59m 37s\n",
            "19:\tlearn: 1.3498677\ttotal: 1m 12s\tremaining: 59m 4s\n",
            "20:\tlearn: 1.3426799\ttotal: 1m 15s\tremaining: 58m 36s\n",
            "21:\tlearn: 1.3356836\ttotal: 1m 18s\tremaining: 58m 18s\n",
            "22:\tlearn: 1.3300854\ttotal: 1m 21s\tremaining: 57m 55s\n",
            "23:\tlearn: 1.3251092\ttotal: 1m 24s\tremaining: 57m 24s\n",
            "24:\tlearn: 1.3199601\ttotal: 1m 27s\tremaining: 57m\n",
            "25:\tlearn: 1.3147636\ttotal: 1m 30s\tremaining: 56m 33s\n",
            "26:\tlearn: 1.3100471\ttotal: 1m 33s\tremaining: 56m 19s\n",
            "27:\tlearn: 1.3045216\ttotal: 1m 36s\tremaining: 55m 57s\n",
            "28:\tlearn: 1.3000917\ttotal: 1m 39s\tremaining: 55m 35s\n",
            "29:\tlearn: 1.2963362\ttotal: 1m 43s\tremaining: 55m 36s\n",
            "30:\tlearn: 1.2919313\ttotal: 1m 46s\tremaining: 55m 27s\n",
            "31:\tlearn: 1.2881725\ttotal: 1m 49s\tremaining: 55m 12s\n",
            "32:\tlearn: 1.2847768\ttotal: 1m 52s\tremaining: 54m 55s\n",
            "33:\tlearn: 1.2809167\ttotal: 1m 55s\tremaining: 54m 49s\n",
            "34:\tlearn: 1.2775497\ttotal: 1m 59s\tremaining: 54m 45s\n",
            "35:\tlearn: 1.2743348\ttotal: 2m 1s\tremaining: 54m 26s\n",
            "36:\tlearn: 1.2714549\ttotal: 2m 4s\tremaining: 54m 9s\n",
            "37:\tlearn: 1.2682565\ttotal: 2m 7s\tremaining: 53m 54s\n",
            "38:\tlearn: 1.2652074\ttotal: 2m 10s\tremaining: 53m 39s\n",
            "39:\tlearn: 1.2623301\ttotal: 2m 13s\tremaining: 53m 25s\n",
            "40:\tlearn: 1.2595061\ttotal: 2m 16s\tremaining: 53m 11s\n",
            "41:\tlearn: 1.2561924\ttotal: 2m 19s\tremaining: 53m 4s\n",
            "42:\tlearn: 1.2539093\ttotal: 2m 22s\tremaining: 52m 49s\n",
            "43:\tlearn: 1.2513333\ttotal: 2m 25s\tremaining: 52m 36s\n",
            "44:\tlearn: 1.2491316\ttotal: 2m 28s\tremaining: 52m 25s\n",
            "45:\tlearn: 1.2458627\ttotal: 2m 31s\tremaining: 52m 15s\n",
            "46:\tlearn: 1.2434641\ttotal: 2m 34s\tremaining: 52m 3s\n",
            "47:\tlearn: 1.2404226\ttotal: 2m 36s\tremaining: 51m 52s\n",
            "48:\tlearn: 1.2387129\ttotal: 2m 39s\tremaining: 51m 40s\n",
            "49:\tlearn: 1.2364172\ttotal: 2m 42s\tremaining: 51m 30s\n",
            "50:\tlearn: 1.2344017\ttotal: 2m 45s\tremaining: 51m 20s\n",
            "51:\tlearn: 1.2324860\ttotal: 2m 48s\tremaining: 51m 10s\n",
            "52:\tlearn: 1.2300422\ttotal: 2m 51s\tremaining: 51m\n",
            "53:\tlearn: 1.2278480\ttotal: 2m 54s\tremaining: 50m 52s\n",
            "54:\tlearn: 1.2259746\ttotal: 2m 57s\tremaining: 50m 43s\n",
            "55:\tlearn: 1.2241884\ttotal: 3m\tremaining: 50m 36s\n",
            "56:\tlearn: 1.2219082\ttotal: 3m 3s\tremaining: 50m 33s\n",
            "57:\tlearn: 1.2200655\ttotal: 3m 6s\tremaining: 50m 28s\n",
            "58:\tlearn: 1.2181710\ttotal: 3m 9s\tremaining: 50m 20s\n",
            "59:\tlearn: 1.2159987\ttotal: 3m 12s\tremaining: 50m 13s\n",
            "60:\tlearn: 1.2140895\ttotal: 3m 15s\tremaining: 50m 8s\n",
            "61:\tlearn: 1.2122848\ttotal: 3m 18s\tremaining: 50m\n",
            "62:\tlearn: 1.2106374\ttotal: 3m 21s\tremaining: 49m 54s\n",
            "63:\tlearn: 1.2092701\ttotal: 3m 24s\tremaining: 49m 48s\n",
            "64:\tlearn: 1.2077021\ttotal: 3m 27s\tremaining: 49m 40s\n",
            "65:\tlearn: 1.2063568\ttotal: 3m 30s\tremaining: 49m 33s\n",
            "66:\tlearn: 1.2051559\ttotal: 3m 33s\tremaining: 49m 26s\n",
            "67:\tlearn: 1.2038021\ttotal: 3m 35s\tremaining: 49m 19s\n",
            "68:\tlearn: 1.2021683\ttotal: 3m 38s\tremaining: 49m 12s\n",
            "69:\tlearn: 1.2006938\ttotal: 3m 41s\tremaining: 49m 5s\n",
            "70:\tlearn: 1.1988882\ttotal: 3m 44s\tremaining: 49m\n",
            "71:\tlearn: 1.1974262\ttotal: 3m 47s\tremaining: 48m 53s\n",
            "72:\tlearn: 1.1962019\ttotal: 3m 50s\tremaining: 48m 46s\n",
            "73:\tlearn: 1.1949584\ttotal: 3m 53s\tremaining: 48m 39s\n",
            "74:\tlearn: 1.1935867\ttotal: 3m 56s\tremaining: 48m 32s\n",
            "75:\tlearn: 1.1920987\ttotal: 3m 59s\tremaining: 48m 27s\n",
            "76:\tlearn: 1.1907613\ttotal: 4m 2s\tremaining: 48m 21s\n",
            "77:\tlearn: 1.1895019\ttotal: 4m 5s\tremaining: 48m 19s\n",
            "78:\tlearn: 1.1882040\ttotal: 4m 8s\tremaining: 48m 13s\n",
            "79:\tlearn: 1.1868578\ttotal: 4m 11s\tremaining: 48m 7s\n",
            "80:\tlearn: 1.1856934\ttotal: 4m 13s\tremaining: 48m 1s\n",
            "81:\tlearn: 1.1845614\ttotal: 4m 16s\tremaining: 47m 55s\n",
            "82:\tlearn: 1.1836236\ttotal: 4m 19s\tremaining: 47m 50s\n",
            "83:\tlearn: 1.1823065\ttotal: 4m 22s\tremaining: 47m 44s\n",
            "84:\tlearn: 1.1812695\ttotal: 4m 25s\tremaining: 47m 39s\n",
            "85:\tlearn: 1.1800225\ttotal: 4m 28s\tremaining: 47m 34s\n",
            "86:\tlearn: 1.1787843\ttotal: 4m 31s\tremaining: 47m 29s\n",
            "87:\tlearn: 1.1775700\ttotal: 4m 34s\tremaining: 47m 23s\n",
            "88:\tlearn: 1.1763723\ttotal: 4m 37s\tremaining: 47m 18s\n",
            "89:\tlearn: 1.1751553\ttotal: 4m 40s\tremaining: 47m 12s\n",
            "90:\tlearn: 1.1739057\ttotal: 4m 43s\tremaining: 47m 7s\n",
            "91:\tlearn: 1.1727446\ttotal: 4m 45s\tremaining: 47m 1s\n",
            "92:\tlearn: 1.1716294\ttotal: 4m 48s\tremaining: 46m 56s\n",
            "93:\tlearn: 1.1705592\ttotal: 4m 51s\tremaining: 46m 52s\n",
            "94:\tlearn: 1.1694867\ttotal: 4m 54s\tremaining: 46m 47s\n",
            "95:\tlearn: 1.1681130\ttotal: 4m 57s\tremaining: 46m 43s\n",
            "96:\tlearn: 1.1672010\ttotal: 5m\tremaining: 46m 37s\n",
            "97:\tlearn: 1.1660194\ttotal: 5m 3s\tremaining: 46m 32s\n",
            "98:\tlearn: 1.1650388\ttotal: 5m 6s\tremaining: 46m 27s\n",
            "99:\tlearn: 1.1641923\ttotal: 5m 9s\tremaining: 46m 22s\n",
            "100:\tlearn: 1.1630458\ttotal: 5m 12s\tremaining: 46m 17s\n",
            "101:\tlearn: 1.1619602\ttotal: 5m 15s\tremaining: 46m 13s\n",
            "102:\tlearn: 1.1610309\ttotal: 5m 18s\tremaining: 46m 10s\n",
            "103:\tlearn: 1.1600808\ttotal: 5m 20s\tremaining: 46m 5s\n",
            "104:\tlearn: 1.1589984\ttotal: 5m 23s\tremaining: 46m\n",
            "105:\tlearn: 1.1577182\ttotal: 5m 26s\tremaining: 45m 57s\n",
            "106:\tlearn: 1.1567124\ttotal: 5m 30s\tremaining: 45m 55s\n",
            "107:\tlearn: 1.1557293\ttotal: 5m 33s\tremaining: 45m 51s\n",
            "108:\tlearn: 1.1546419\ttotal: 5m 35s\tremaining: 45m 46s\n",
            "109:\tlearn: 1.1534501\ttotal: 5m 38s\tremaining: 45m 41s\n",
            "110:\tlearn: 1.1525521\ttotal: 5m 41s\tremaining: 45m 37s\n",
            "111:\tlearn: 1.1516371\ttotal: 5m 44s\tremaining: 45m 33s\n",
            "112:\tlearn: 1.1505291\ttotal: 5m 47s\tremaining: 45m 28s\n",
            "113:\tlearn: 1.1495300\ttotal: 5m 50s\tremaining: 45m 26s\n",
            "114:\tlearn: 1.1488050\ttotal: 5m 53s\tremaining: 45m 22s\n",
            "115:\tlearn: 1.1479360\ttotal: 5m 56s\tremaining: 45m 17s\n",
            "116:\tlearn: 1.1468259\ttotal: 5m 59s\tremaining: 45m 13s\n",
            "117:\tlearn: 1.1459154\ttotal: 6m 2s\tremaining: 45m 9s\n",
            "118:\tlearn: 1.1451412\ttotal: 6m 5s\tremaining: 45m 4s\n",
            "119:\tlearn: 1.1439603\ttotal: 6m 8s\tremaining: 45m 1s\n",
            "120:\tlearn: 1.1430618\ttotal: 6m 11s\tremaining: 44m 56s\n",
            "121:\tlearn: 1.1422080\ttotal: 6m 14s\tremaining: 44m 52s\n",
            "122:\tlearn: 1.1413432\ttotal: 6m 16s\tremaining: 44m 47s\n",
            "123:\tlearn: 1.1405724\ttotal: 6m 19s\tremaining: 44m 43s\n",
            "124:\tlearn: 1.1397222\ttotal: 6m 22s\tremaining: 44m 38s\n",
            "125:\tlearn: 1.1389278\ttotal: 6m 25s\tremaining: 44m 34s\n",
            "126:\tlearn: 1.1380195\ttotal: 6m 28s\tremaining: 44m 30s\n",
            "127:\tlearn: 1.1369989\ttotal: 6m 31s\tremaining: 44m 26s\n",
            "128:\tlearn: 1.1360593\ttotal: 6m 34s\tremaining: 44m 22s\n",
            "129:\tlearn: 1.1348581\ttotal: 6m 37s\tremaining: 44m 19s\n",
            "130:\tlearn: 1.1340111\ttotal: 6m 40s\tremaining: 44m 15s\n",
            "131:\tlearn: 1.1332467\ttotal: 6m 43s\tremaining: 44m 11s\n",
            "132:\tlearn: 1.1325476\ttotal: 6m 46s\tremaining: 44m 7s\n",
            "133:\tlearn: 1.1316972\ttotal: 6m 49s\tremaining: 44m 4s\n",
            "134:\tlearn: 1.1308865\ttotal: 6m 52s\tremaining: 44m\n",
            "135:\tlearn: 1.1299037\ttotal: 6m 54s\tremaining: 43m 56s\n",
            "136:\tlearn: 1.1290084\ttotal: 6m 58s\tremaining: 43m 53s\n",
            "137:\tlearn: 1.1281930\ttotal: 7m 1s\tremaining: 43m 50s\n",
            "138:\tlearn: 1.1273610\ttotal: 7m 4s\tremaining: 43m 47s\n",
            "139:\tlearn: 1.1266114\ttotal: 7m 7s\tremaining: 43m 43s\n",
            "140:\tlearn: 1.1255292\ttotal: 7m 10s\tremaining: 43m 41s\n",
            "141:\tlearn: 1.1246661\ttotal: 7m 13s\tremaining: 43m 37s\n",
            "142:\tlearn: 1.1237800\ttotal: 7m 16s\tremaining: 43m 36s\n",
            "143:\tlearn: 1.1230866\ttotal: 7m 19s\tremaining: 43m 33s\n",
            "144:\tlearn: 1.1223496\ttotal: 7m 22s\tremaining: 43m 30s\n",
            "145:\tlearn: 1.1216522\ttotal: 7m 25s\tremaining: 43m 26s\n",
            "146:\tlearn: 1.1209097\ttotal: 7m 28s\tremaining: 43m 22s\n",
            "147:\tlearn: 1.1201637\ttotal: 7m 31s\tremaining: 43m 18s\n",
            "148:\tlearn: 1.1193451\ttotal: 7m 34s\tremaining: 43m 14s\n",
            "149:\tlearn: 1.1185413\ttotal: 7m 37s\tremaining: 43m 10s\n",
            "150:\tlearn: 1.1178936\ttotal: 7m 40s\tremaining: 43m 7s\n",
            "151:\tlearn: 1.1171582\ttotal: 7m 43s\tremaining: 43m 5s\n",
            "152:\tlearn: 1.1166566\ttotal: 7m 46s\tremaining: 43m 1s\n",
            "153:\tlearn: 1.1159422\ttotal: 7m 49s\tremaining: 42m 56s\n",
            "154:\tlearn: 1.1153675\ttotal: 7m 52s\tremaining: 42m 54s\n",
            "155:\tlearn: 1.1147060\ttotal: 7m 55s\tremaining: 42m 54s\n",
            "156:\tlearn: 1.1139950\ttotal: 7m 59s\tremaining: 42m 53s\n",
            "157:\tlearn: 1.1131647\ttotal: 8m 3s\tremaining: 42m 54s\n",
            "158:\tlearn: 1.1124496\ttotal: 8m 6s\tremaining: 42m 51s\n",
            "159:\tlearn: 1.1117173\ttotal: 8m 9s\tremaining: 42m 48s\n",
            "160:\tlearn: 1.1110760\ttotal: 8m 12s\tremaining: 42m 44s\n",
            "161:\tlearn: 1.1103094\ttotal: 8m 14s\tremaining: 42m 40s\n",
            "162:\tlearn: 1.1096305\ttotal: 8m 18s\tremaining: 42m 38s\n",
            "163:\tlearn: 1.1090929\ttotal: 8m 21s\tremaining: 42m 35s\n",
            "164:\tlearn: 1.1084868\ttotal: 8m 24s\tremaining: 42m 33s\n",
            "165:\tlearn: 1.1079763\ttotal: 8m 27s\tremaining: 42m 30s\n",
            "166:\tlearn: 1.1072731\ttotal: 8m 30s\tremaining: 42m 27s\n",
            "167:\tlearn: 1.1066412\ttotal: 8m 34s\tremaining: 42m 25s\n",
            "168:\tlearn: 1.1060037\ttotal: 8m 36s\tremaining: 42m 21s\n",
            "169:\tlearn: 1.1053778\ttotal: 8m 39s\tremaining: 42m 17s\n",
            "170:\tlearn: 1.1047854\ttotal: 8m 42s\tremaining: 42m 13s\n",
            "171:\tlearn: 1.1043199\ttotal: 8m 45s\tremaining: 42m 9s\n",
            "172:\tlearn: 1.1038179\ttotal: 8m 48s\tremaining: 42m 6s\n",
            "173:\tlearn: 1.1031885\ttotal: 8m 51s\tremaining: 42m 2s\n",
            "174:\tlearn: 1.1024659\ttotal: 8m 54s\tremaining: 41m 58s\n",
            "175:\tlearn: 1.1018148\ttotal: 8m 57s\tremaining: 41m 55s\n",
            "176:\tlearn: 1.1011790\ttotal: 9m\tremaining: 41m 52s\n",
            "177:\tlearn: 1.1006649\ttotal: 9m 3s\tremaining: 41m 49s\n",
            "178:\tlearn: 1.1001482\ttotal: 9m 6s\tremaining: 41m 45s\n",
            "179:\tlearn: 1.0996525\ttotal: 9m 9s\tremaining: 41m 41s\n",
            "180:\tlearn: 1.0990446\ttotal: 9m 12s\tremaining: 41m 37s\n",
            "181:\tlearn: 1.0984129\ttotal: 9m 15s\tremaining: 41m 35s\n",
            "182:\tlearn: 1.0978248\ttotal: 9m 18s\tremaining: 41m 33s\n",
            "183:\tlearn: 1.0972499\ttotal: 9m 21s\tremaining: 41m 29s\n",
            "184:\tlearn: 1.0965283\ttotal: 9m 24s\tremaining: 41m 27s\n",
            "185:\tlearn: 1.0959949\ttotal: 9m 27s\tremaining: 41m 25s\n",
            "186:\tlearn: 1.0954921\ttotal: 9m 30s\tremaining: 41m 22s\n",
            "187:\tlearn: 1.0950381\ttotal: 9m 33s\tremaining: 41m 17s\n",
            "188:\tlearn: 1.0945790\ttotal: 9m 36s\tremaining: 41m 12s\n",
            "189:\tlearn: 1.0941160\ttotal: 9m 39s\tremaining: 41m 8s\n",
            "190:\tlearn: 1.0935131\ttotal: 9m 41s\tremaining: 41m 4s\n",
            "191:\tlearn: 1.0931110\ttotal: 9m 44s\tremaining: 41m\n",
            "192:\tlearn: 1.0927064\ttotal: 9m 47s\tremaining: 40m 56s\n",
            "193:\tlearn: 1.0923175\ttotal: 9m 50s\tremaining: 40m 52s\n",
            "194:\tlearn: 1.0919105\ttotal: 9m 52s\tremaining: 40m 47s\n",
            "195:\tlearn: 1.0914089\ttotal: 9m 55s\tremaining: 40m 42s\n",
            "196:\tlearn: 1.0908920\ttotal: 9m 58s\tremaining: 40m 38s\n",
            "197:\tlearn: 1.0902217\ttotal: 10m 1s\tremaining: 40m 35s\n",
            "198:\tlearn: 1.0897984\ttotal: 10m 3s\tremaining: 40m 31s\n",
            "199:\tlearn: 1.0894521\ttotal: 10m 6s\tremaining: 40m 26s\n",
            "200:\tlearn: 1.0890597\ttotal: 10m 9s\tremaining: 40m 21s\n",
            "201:\tlearn: 1.0885085\ttotal: 10m 12s\tremaining: 40m 18s\n",
            "202:\tlearn: 1.0880620\ttotal: 10m 14s\tremaining: 40m 13s\n",
            "203:\tlearn: 1.0875010\ttotal: 10m 18s\tremaining: 40m 11s\n",
            "204:\tlearn: 1.0870633\ttotal: 10m 21s\tremaining: 40m 11s\n",
            "205:\tlearn: 1.0865533\ttotal: 10m 25s\tremaining: 40m 9s\n",
            "206:\tlearn: 1.0861083\ttotal: 10m 28s\tremaining: 40m 6s\n",
            "207:\tlearn: 1.0856975\ttotal: 10m 31s\tremaining: 40m 2s\n",
            "208:\tlearn: 1.0852975\ttotal: 10m 34s\tremaining: 40m\n",
            "209:\tlearn: 1.0848138\ttotal: 10m 37s\tremaining: 39m 56s\n",
            "210:\tlearn: 1.0843502\ttotal: 10m 40s\tremaining: 39m 53s\n",
            "211:\tlearn: 1.0839297\ttotal: 10m 42s\tremaining: 39m 49s\n",
            "212:\tlearn: 1.0835412\ttotal: 10m 46s\tremaining: 39m 46s\n",
            "213:\tlearn: 1.0831831\ttotal: 10m 49s\tremaining: 39m 45s\n",
            "214:\tlearn: 1.0825309\ttotal: 10m 53s\tremaining: 39m 44s\n",
            "215:\tlearn: 1.0819959\ttotal: 10m 56s\tremaining: 39m 43s\n",
            "216:\tlearn: 1.0815686\ttotal: 11m\tremaining: 39m 41s\n",
            "217:\tlearn: 1.0811614\ttotal: 11m 3s\tremaining: 39m 39s\n",
            "218:\tlearn: 1.0806744\ttotal: 11m 6s\tremaining: 39m 36s\n",
            "219:\tlearn: 1.0801586\ttotal: 11m 9s\tremaining: 39m 32s\n",
            "220:\tlearn: 1.0797663\ttotal: 11m 12s\tremaining: 39m 30s\n",
            "221:\tlearn: 1.0793676\ttotal: 11m 15s\tremaining: 39m 28s\n",
            "222:\tlearn: 1.0789820\ttotal: 11m 19s\tremaining: 39m 26s\n",
            "223:\tlearn: 1.0785708\ttotal: 11m 22s\tremaining: 39m 24s\n",
            "224:\tlearn: 1.0781998\ttotal: 11m 25s\tremaining: 39m 21s\n",
            "225:\tlearn: 1.0777064\ttotal: 11m 28s\tremaining: 39m 18s\n",
            "226:\tlearn: 1.0772685\ttotal: 11m 32s\tremaining: 39m 16s\n",
            "227:\tlearn: 1.0768022\ttotal: 11m 35s\tremaining: 39m 16s\n",
            "228:\tlearn: 1.0763618\ttotal: 11m 39s\tremaining: 39m 14s\n",
            "229:\tlearn: 1.0760305\ttotal: 11m 42s\tremaining: 39m 11s\n",
            "230:\tlearn: 1.0755980\ttotal: 11m 45s\tremaining: 39m 9s\n",
            "231:\tlearn: 1.0752128\ttotal: 11m 48s\tremaining: 39m 6s\n",
            "232:\tlearn: 1.0748094\ttotal: 11m 51s\tremaining: 39m 3s\n",
            "233:\tlearn: 1.0743325\ttotal: 11m 55s\tremaining: 39m 1s\n",
            "234:\tlearn: 1.0739797\ttotal: 11m 58s\tremaining: 39m\n",
            "235:\tlearn: 1.0735934\ttotal: 12m 2s\tremaining: 38m 58s\n",
            "236:\tlearn: 1.0732056\ttotal: 12m 5s\tremaining: 38m 54s\n",
            "237:\tlearn: 1.0727810\ttotal: 12m 7s\tremaining: 38m 50s\n",
            "238:\tlearn: 1.0723765\ttotal: 12m 10s\tremaining: 38m 46s\n",
            "239:\tlearn: 1.0720066\ttotal: 12m 13s\tremaining: 38m 43s\n",
            "240:\tlearn: 1.0716691\ttotal: 12m 16s\tremaining: 38m 39s\n",
            "241:\tlearn: 1.0711929\ttotal: 12m 19s\tremaining: 38m 35s\n",
            "242:\tlearn: 1.0708627\ttotal: 12m 21s\tremaining: 38m 31s\n",
            "243:\tlearn: 1.0705701\ttotal: 12m 24s\tremaining: 38m 27s\n",
            "244:\tlearn: 1.0701421\ttotal: 12m 27s\tremaining: 38m 24s\n",
            "245:\tlearn: 1.0698580\ttotal: 12m 30s\tremaining: 38m 20s\n",
            "246:\tlearn: 1.0695111\ttotal: 12m 33s\tremaining: 38m 17s\n",
            "247:\tlearn: 1.0691343\ttotal: 12m 36s\tremaining: 38m 14s\n",
            "248:\tlearn: 1.0687557\ttotal: 12m 39s\tremaining: 38m 12s\n",
            "249:\tlearn: 1.0684386\ttotal: 12m 43s\tremaining: 38m 9s\n",
            "250:\tlearn: 1.0680597\ttotal: 12m 46s\tremaining: 38m 5s\n",
            "251:\tlearn: 1.0676626\ttotal: 12m 49s\tremaining: 38m 2s\n",
            "252:\tlearn: 1.0673210\ttotal: 12m 52s\tremaining: 38m\n",
            "253:\tlearn: 1.0668934\ttotal: 12m 55s\tremaining: 37m 57s\n",
            "254:\tlearn: 1.0665068\ttotal: 12m 58s\tremaining: 37m 55s\n",
            "255:\tlearn: 1.0662130\ttotal: 13m 1s\tremaining: 37m 51s\n",
            "256:\tlearn: 1.0659666\ttotal: 13m 4s\tremaining: 37m 47s\n",
            "257:\tlearn: 1.0656992\ttotal: 13m 7s\tremaining: 37m 43s\n",
            "258:\tlearn: 1.0653301\ttotal: 13m 10s\tremaining: 37m 41s\n",
            "259:\tlearn: 1.0650857\ttotal: 13m 13s\tremaining: 37m 38s\n",
            "260:\tlearn: 1.0647620\ttotal: 13m 16s\tremaining: 37m 35s\n",
            "261:\tlearn: 1.0644705\ttotal: 13m 19s\tremaining: 37m 33s\n",
            "262:\tlearn: 1.0641065\ttotal: 13m 22s\tremaining: 37m 29s\n",
            "263:\tlearn: 1.0638129\ttotal: 13m 25s\tremaining: 37m 25s\n",
            "264:\tlearn: 1.0635490\ttotal: 13m 28s\tremaining: 37m 22s\n",
            "265:\tlearn: 1.0630184\ttotal: 13m 31s\tremaining: 37m 19s\n",
            "266:\tlearn: 1.0627615\ttotal: 13m 34s\tremaining: 37m 16s\n",
            "267:\tlearn: 1.0625005\ttotal: 13m 37s\tremaining: 37m 12s\n",
            "268:\tlearn: 1.0621982\ttotal: 13m 40s\tremaining: 37m 9s\n",
            "269:\tlearn: 1.0618165\ttotal: 13m 43s\tremaining: 37m 5s\n",
            "270:\tlearn: 1.0614475\ttotal: 13m 46s\tremaining: 37m 2s\n",
            "271:\tlearn: 1.0611078\ttotal: 13m 48s\tremaining: 36m 58s\n",
            "272:\tlearn: 1.0608213\ttotal: 13m 51s\tremaining: 36m 54s\n",
            "273:\tlearn: 1.0605099\ttotal: 13m 54s\tremaining: 36m 50s\n",
            "274:\tlearn: 1.0602553\ttotal: 13m 57s\tremaining: 36m 47s\n",
            "275:\tlearn: 1.0599416\ttotal: 14m\tremaining: 36m 44s\n",
            "276:\tlearn: 1.0596362\ttotal: 14m 3s\tremaining: 36m 41s\n",
            "277:\tlearn: 1.0592912\ttotal: 14m 6s\tremaining: 36m 38s\n",
            "278:\tlearn: 1.0589546\ttotal: 14m 9s\tremaining: 36m 35s\n",
            "279:\tlearn: 1.0586648\ttotal: 14m 12s\tremaining: 36m 32s\n",
            "280:\tlearn: 1.0583469\ttotal: 14m 15s\tremaining: 36m 29s\n",
            "281:\tlearn: 1.0579913\ttotal: 14m 18s\tremaining: 36m 26s\n",
            "282:\tlearn: 1.0577101\ttotal: 14m 21s\tremaining: 36m 23s\n",
            "283:\tlearn: 1.0574869\ttotal: 14m 25s\tremaining: 36m 20s\n",
            "284:\tlearn: 1.0572028\ttotal: 14m 28s\tremaining: 36m 17s\n",
            "285:\tlearn: 1.0569805\ttotal: 14m 31s\tremaining: 36m 14s\n",
            "286:\tlearn: 1.0567104\ttotal: 14m 34s\tremaining: 36m 12s\n",
            "287:\tlearn: 1.0564405\ttotal: 14m 37s\tremaining: 36m 8s\n",
            "288:\tlearn: 1.0561330\ttotal: 14m 39s\tremaining: 36m 4s\n",
            "289:\tlearn: 1.0558048\ttotal: 14m 42s\tremaining: 36m\n",
            "290:\tlearn: 1.0555710\ttotal: 14m 44s\tremaining: 35m 55s\n",
            "291:\tlearn: 1.0552719\ttotal: 14m 47s\tremaining: 35m 52s\n",
            "292:\tlearn: 1.0549582\ttotal: 14m 50s\tremaining: 35m 49s\n",
            "293:\tlearn: 1.0545804\ttotal: 14m 53s\tremaining: 35m 46s\n",
            "294:\tlearn: 1.0543666\ttotal: 14m 56s\tremaining: 35m 42s\n",
            "295:\tlearn: 1.0541846\ttotal: 14m 59s\tremaining: 35m 39s\n",
            "296:\tlearn: 1.0539100\ttotal: 15m 3s\tremaining: 35m 37s\n",
            "297:\tlearn: 1.0535887\ttotal: 15m 6s\tremaining: 35m 35s\n",
            "298:\tlearn: 1.0532333\ttotal: 15m 9s\tremaining: 35m 33s\n",
            "299:\tlearn: 1.0530479\ttotal: 15m 13s\tremaining: 35m 30s\n",
            "300:\tlearn: 1.0528175\ttotal: 15m 16s\tremaining: 35m 27s\n",
            "301:\tlearn: 1.0525441\ttotal: 15m 19s\tremaining: 35m 24s\n",
            "302:\tlearn: 1.0522452\ttotal: 15m 21s\tremaining: 35m 20s\n",
            "303:\tlearn: 1.0520719\ttotal: 15m 24s\tremaining: 35m 16s\n",
            "304:\tlearn: 1.0518299\ttotal: 15m 27s\tremaining: 35m 12s\n",
            "305:\tlearn: 1.0516082\ttotal: 15m 29s\tremaining: 35m 9s\n",
            "306:\tlearn: 1.0512521\ttotal: 15m 32s\tremaining: 35m 5s\n",
            "307:\tlearn: 1.0510061\ttotal: 15m 35s\tremaining: 35m 2s\n",
            "308:\tlearn: 1.0507599\ttotal: 15m 38s\tremaining: 34m 59s\n",
            "309:\tlearn: 1.0503782\ttotal: 15m 41s\tremaining: 34m 56s\n",
            "310:\tlearn: 1.0501242\ttotal: 15m 44s\tremaining: 34m 52s\n",
            "311:\tlearn: 1.0498764\ttotal: 15m 47s\tremaining: 34m 49s\n",
            "312:\tlearn: 1.0495628\ttotal: 15m 50s\tremaining: 34m 46s\n",
            "313:\tlearn: 1.0493459\ttotal: 15m 53s\tremaining: 34m 43s\n",
            "314:\tlearn: 1.0490890\ttotal: 15m 56s\tremaining: 34m 40s\n",
            "315:\tlearn: 1.0487759\ttotal: 15m 59s\tremaining: 34m 37s\n",
            "316:\tlearn: 1.0484146\ttotal: 16m 3s\tremaining: 34m 35s\n",
            "317:\tlearn: 1.0480894\ttotal: 16m 6s\tremaining: 34m 32s\n",
            "318:\tlearn: 1.0478088\ttotal: 16m 9s\tremaining: 34m 30s\n",
            "319:\tlearn: 1.0475905\ttotal: 16m 12s\tremaining: 34m 27s\n",
            "320:\tlearn: 1.0473602\ttotal: 16m 15s\tremaining: 34m 24s\n",
            "321:\tlearn: 1.0471296\ttotal: 16m 18s\tremaining: 34m 21s\n",
            "322:\tlearn: 1.0468195\ttotal: 16m 22s\tremaining: 34m 18s\n",
            "323:\tlearn: 1.0465692\ttotal: 16m 25s\tremaining: 34m 15s\n",
            "324:\tlearn: 1.0462931\ttotal: 16m 28s\tremaining: 34m 12s\n",
            "325:\tlearn: 1.0460547\ttotal: 16m 30s\tremaining: 34m 8s\n",
            "326:\tlearn: 1.0457885\ttotal: 16m 33s\tremaining: 34m 5s\n",
            "327:\tlearn: 1.0455771\ttotal: 16m 36s\tremaining: 34m 2s\n",
            "328:\tlearn: 1.0454089\ttotal: 16m 39s\tremaining: 33m 58s\n",
            "329:\tlearn: 1.0451763\ttotal: 16m 42s\tremaining: 33m 55s\n",
            "330:\tlearn: 1.0448161\ttotal: 16m 45s\tremaining: 33m 52s\n",
            "331:\tlearn: 1.0445799\ttotal: 16m 48s\tremaining: 33m 49s\n",
            "332:\tlearn: 1.0443732\ttotal: 16m 51s\tremaining: 33m 46s\n",
            "333:\tlearn: 1.0441211\ttotal: 16m 54s\tremaining: 33m 43s\n",
            "334:\tlearn: 1.0438202\ttotal: 16m 57s\tremaining: 33m 40s\n",
            "335:\tlearn: 1.0435702\ttotal: 17m 1s\tremaining: 33m 37s\n",
            "336:\tlearn: 1.0434053\ttotal: 17m 4s\tremaining: 33m 35s\n",
            "337:\tlearn: 1.0432386\ttotal: 17m 7s\tremaining: 33m 31s\n",
            "338:\tlearn: 1.0430582\ttotal: 17m 10s\tremaining: 33m 28s\n",
            "339:\tlearn: 1.0427901\ttotal: 17m 13s\tremaining: 33m 26s\n",
            "340:\tlearn: 1.0425112\ttotal: 17m 16s\tremaining: 33m 23s\n",
            "341:\tlearn: 1.0423103\ttotal: 17m 19s\tremaining: 33m 20s\n",
            "342:\tlearn: 1.0421477\ttotal: 17m 22s\tremaining: 33m 17s\n",
            "343:\tlearn: 1.0418681\ttotal: 17m 25s\tremaining: 33m 14s\n",
            "344:\tlearn: 1.0416760\ttotal: 17m 28s\tremaining: 33m 11s\n",
            "345:\tlearn: 1.0414362\ttotal: 17m 32s\tremaining: 33m 8s\n",
            "346:\tlearn: 1.0412975\ttotal: 17m 35s\tremaining: 33m 5s\n",
            "347:\tlearn: 1.0411746\ttotal: 17m 38s\tremaining: 33m 2s\n",
            "348:\tlearn: 1.0409432\ttotal: 17m 41s\tremaining: 32m 59s\n",
            "349:\tlearn: 1.0408034\ttotal: 17m 44s\tremaining: 32m 56s\n",
            "350:\tlearn: 1.0406004\ttotal: 17m 47s\tremaining: 32m 53s\n",
            "351:\tlearn: 1.0403681\ttotal: 17m 50s\tremaining: 32m 51s\n",
            "352:\tlearn: 1.0401516\ttotal: 17m 54s\tremaining: 32m 48s\n",
            "353:\tlearn: 1.0399768\ttotal: 17m 57s\tremaining: 32m 46s\n",
            "354:\tlearn: 1.0397800\ttotal: 18m\tremaining: 32m 43s\n",
            "355:\tlearn: 1.0395436\ttotal: 18m 3s\tremaining: 32m 40s\n",
            "356:\tlearn: 1.0393073\ttotal: 18m 7s\tremaining: 32m 38s\n",
            "357:\tlearn: 1.0391155\ttotal: 18m 10s\tremaining: 32m 35s\n",
            "358:\tlearn: 1.0389471\ttotal: 18m 13s\tremaining: 32m 33s\n",
            "359:\tlearn: 1.0387312\ttotal: 18m 17s\tremaining: 32m 30s\n",
            "360:\tlearn: 1.0384579\ttotal: 18m 20s\tremaining: 32m 27s\n",
            "361:\tlearn: 1.0382015\ttotal: 18m 23s\tremaining: 32m 25s\n",
            "362:\tlearn: 1.0379692\ttotal: 18m 26s\tremaining: 32m 22s\n",
            "363:\tlearn: 1.0376969\ttotal: 18m 30s\tremaining: 32m 20s\n",
            "364:\tlearn: 1.0375803\ttotal: 18m 33s\tremaining: 32m 17s\n",
            "365:\tlearn: 1.0373929\ttotal: 18m 36s\tremaining: 32m 13s\n",
            "366:\tlearn: 1.0372308\ttotal: 18m 39s\tremaining: 32m 10s\n",
            "367:\tlearn: 1.0370247\ttotal: 18m 42s\tremaining: 32m 7s\n",
            "368:\tlearn: 1.0368241\ttotal: 18m 44s\tremaining: 32m 3s\n",
            "369:\tlearn: 1.0365984\ttotal: 18m 47s\tremaining: 31m 59s\n",
            "370:\tlearn: 1.0363959\ttotal: 18m 50s\tremaining: 31m 56s\n",
            "371:\tlearn: 1.0362360\ttotal: 18m 53s\tremaining: 31m 54s\n",
            "372:\tlearn: 1.0359814\ttotal: 18m 56s\tremaining: 31m 50s\n",
            "373:\tlearn: 1.0357589\ttotal: 18m 59s\tremaining: 31m 48s\n",
            "374:\tlearn: 1.0354619\ttotal: 19m 3s\tremaining: 31m 45s\n",
            "375:\tlearn: 1.0352756\ttotal: 19m 6s\tremaining: 31m 42s\n",
            "376:\tlearn: 1.0350670\ttotal: 19m 9s\tremaining: 31m 39s\n",
            "377:\tlearn: 1.0348333\ttotal: 19m 12s\tremaining: 31m 35s\n",
            "378:\tlearn: 1.0346127\ttotal: 19m 14s\tremaining: 31m 32s\n",
            "379:\tlearn: 1.0344267\ttotal: 19m 17s\tremaining: 31m 28s\n",
            "380:\tlearn: 1.0343040\ttotal: 19m 20s\tremaining: 31m 24s\n",
            "381:\tlearn: 1.0340631\ttotal: 19m 23s\tremaining: 31m 21s\n",
            "382:\tlearn: 1.0337975\ttotal: 19m 25s\tremaining: 31m 18s\n",
            "383:\tlearn: 1.0335697\ttotal: 19m 28s\tremaining: 31m 14s\n",
            "384:\tlearn: 1.0333684\ttotal: 19m 31s\tremaining: 31m 11s\n",
            "385:\tlearn: 1.0331314\ttotal: 19m 34s\tremaining: 31m 8s\n",
            "386:\tlearn: 1.0329221\ttotal: 19m 37s\tremaining: 31m 5s\n",
            "387:\tlearn: 1.0327668\ttotal: 19m 40s\tremaining: 31m 2s\n",
            "388:\tlearn: 1.0326186\ttotal: 19m 43s\tremaining: 30m 59s\n",
            "389:\tlearn: 1.0324790\ttotal: 19m 46s\tremaining: 30m 56s\n",
            "390:\tlearn: 1.0322131\ttotal: 19m 50s\tremaining: 30m 53s\n",
            "391:\tlearn: 1.0320604\ttotal: 19m 53s\tremaining: 30m 50s\n",
            "392:\tlearn: 1.0318186\ttotal: 19m 56s\tremaining: 30m 48s\n",
            "393:\tlearn: 1.0315866\ttotal: 19m 59s\tremaining: 30m 45s\n",
            "394:\tlearn: 1.0314365\ttotal: 20m 2s\tremaining: 30m 42s\n",
            "395:\tlearn: 1.0313103\ttotal: 20m 5s\tremaining: 30m 39s\n",
            "396:\tlearn: 1.0311485\ttotal: 20m 9s\tremaining: 30m 36s\n",
            "397:\tlearn: 1.0309845\ttotal: 20m 12s\tremaining: 30m 33s\n",
            "398:\tlearn: 1.0308131\ttotal: 20m 16s\tremaining: 30m 31s\n",
            "399:\tlearn: 1.0306035\ttotal: 20m 19s\tremaining: 30m 29s\n",
            "400:\tlearn: 1.0303948\ttotal: 20m 22s\tremaining: 30m 26s\n",
            "401:\tlearn: 1.0302291\ttotal: 20m 25s\tremaining: 30m 23s\n",
            "402:\tlearn: 1.0300276\ttotal: 20m 28s\tremaining: 30m 20s\n",
            "403:\tlearn: 1.0298108\ttotal: 20m 32s\tremaining: 30m 17s\n",
            "404:\tlearn: 1.0295725\ttotal: 20m 35s\tremaining: 30m 14s\n",
            "405:\tlearn: 1.0294039\ttotal: 20m 38s\tremaining: 30m 12s\n",
            "406:\tlearn: 1.0292233\ttotal: 20m 41s\tremaining: 30m 9s\n",
            "407:\tlearn: 1.0289960\ttotal: 20m 45s\tremaining: 30m 6s\n",
            "408:\tlearn: 1.0288145\ttotal: 20m 48s\tremaining: 30m 3s\n",
            "409:\tlearn: 1.0285062\ttotal: 20m 51s\tremaining: 30m\n",
            "410:\tlearn: 1.0283186\ttotal: 20m 54s\tremaining: 29m 57s\n",
            "411:\tlearn: 1.0281465\ttotal: 20m 57s\tremaining: 29m 54s\n",
            "412:\tlearn: 1.0280194\ttotal: 21m\tremaining: 29m 51s\n",
            "413:\tlearn: 1.0278127\ttotal: 21m 3s\tremaining: 29m 47s\n",
            "414:\tlearn: 1.0276472\ttotal: 21m 5s\tremaining: 29m 44s\n",
            "415:\tlearn: 1.0274395\ttotal: 21m 8s\tremaining: 29m 41s\n",
            "416:\tlearn: 1.0272960\ttotal: 21m 11s\tremaining: 29m 37s\n",
            "417:\tlearn: 1.0271476\ttotal: 21m 14s\tremaining: 29m 34s\n",
            "418:\tlearn: 1.0269852\ttotal: 21m 17s\tremaining: 29m 30s\n",
            "419:\tlearn: 1.0268229\ttotal: 21m 20s\tremaining: 29m 27s\n",
            "420:\tlearn: 1.0266817\ttotal: 21m 23s\tremaining: 29m 24s\n",
            "421:\tlearn: 1.0265324\ttotal: 21m 26s\tremaining: 29m 21s\n",
            "422:\tlearn: 1.0263638\ttotal: 21m 29s\tremaining: 29m 18s\n",
            "423:\tlearn: 1.0260869\ttotal: 21m 32s\tremaining: 29m 15s\n",
            "424:\tlearn: 1.0258933\ttotal: 21m 35s\tremaining: 29m 12s\n",
            "425:\tlearn: 1.0256554\ttotal: 21m 38s\tremaining: 29m 9s\n",
            "426:\tlearn: 1.0255032\ttotal: 21m 41s\tremaining: 29m 6s\n",
            "427:\tlearn: 1.0253875\ttotal: 21m 44s\tremaining: 29m 3s\n",
            "428:\tlearn: 1.0252401\ttotal: 21m 47s\tremaining: 29m\n",
            "429:\tlearn: 1.0251913\ttotal: 21m 50s\tremaining: 28m 57s\n",
            "430:\tlearn: 1.0249751\ttotal: 21m 53s\tremaining: 28m 54s\n",
            "431:\tlearn: 1.0247619\ttotal: 21m 56s\tremaining: 28m 51s\n",
            "432:\tlearn: 1.0246172\ttotal: 21m 59s\tremaining: 28m 48s\n",
            "433:\tlearn: 1.0244977\ttotal: 22m 2s\tremaining: 28m 44s\n",
            "434:\tlearn: 1.0243067\ttotal: 22m 5s\tremaining: 28m 41s\n",
            "435:\tlearn: 1.0241601\ttotal: 22m 8s\tremaining: 28m 38s\n",
            "436:\tlearn: 1.0239750\ttotal: 22m 11s\tremaining: 28m 35s\n",
            "437:\tlearn: 1.0237548\ttotal: 22m 14s\tremaining: 28m 32s\n",
            "438:\tlearn: 1.0236361\ttotal: 22m 17s\tremaining: 28m 29s\n",
            "439:\tlearn: 1.0234287\ttotal: 22m 20s\tremaining: 28m 26s\n",
            "440:\tlearn: 1.0232384\ttotal: 22m 23s\tremaining: 28m 23s\n",
            "441:\tlearn: 1.0231022\ttotal: 22m 27s\tremaining: 28m 20s\n",
            "442:\tlearn: 1.0229478\ttotal: 22m 29s\tremaining: 28m 17s\n",
            "443:\tlearn: 1.0228384\ttotal: 22m 33s\tremaining: 28m 14s\n",
            "444:\tlearn: 1.0226670\ttotal: 22m 36s\tremaining: 28m 11s\n",
            "445:\tlearn: 1.0225190\ttotal: 22m 39s\tremaining: 28m 8s\n",
            "446:\tlearn: 1.0224375\ttotal: 22m 42s\tremaining: 28m 5s\n",
            "447:\tlearn: 1.0223119\ttotal: 22m 45s\tremaining: 28m 2s\n",
            "448:\tlearn: 1.0221109\ttotal: 22m 48s\tremaining: 27m 59s\n",
            "449:\tlearn: 1.0218647\ttotal: 22m 51s\tremaining: 27m 56s\n",
            "450:\tlearn: 1.0217191\ttotal: 22m 54s\tremaining: 27m 53s\n",
            "451:\tlearn: 1.0215539\ttotal: 22m 57s\tremaining: 27m 50s\n",
            "452:\tlearn: 1.0213564\ttotal: 23m\tremaining: 27m 47s\n",
            "453:\tlearn: 1.0212158\ttotal: 23m 4s\tremaining: 27m 44s\n",
            "454:\tlearn: 1.0210319\ttotal: 23m 7s\tremaining: 27m 41s\n",
            "455:\tlearn: 1.0208636\ttotal: 23m 10s\tremaining: 27m 39s\n",
            "456:\tlearn: 1.0206957\ttotal: 23m 13s\tremaining: 27m 35s\n",
            "457:\tlearn: 1.0205439\ttotal: 23m 16s\tremaining: 27m 32s\n",
            "458:\tlearn: 1.0203516\ttotal: 23m 19s\tremaining: 27m 29s\n",
            "459:\tlearn: 1.0202358\ttotal: 23m 23s\tremaining: 27m 27s\n",
            "460:\tlearn: 1.0200578\ttotal: 23m 26s\tremaining: 27m 24s\n",
            "461:\tlearn: 1.0198499\ttotal: 23m 29s\tremaining: 27m 21s\n",
            "462:\tlearn: 1.0197184\ttotal: 23m 32s\tremaining: 27m 17s\n",
            "463:\tlearn: 1.0195743\ttotal: 23m 34s\tremaining: 27m 14s\n",
            "464:\tlearn: 1.0194885\ttotal: 23m 37s\tremaining: 27m 10s\n",
            "465:\tlearn: 1.0193220\ttotal: 23m 40s\tremaining: 27m 7s\n",
            "466:\tlearn: 1.0191906\ttotal: 23m 42s\tremaining: 27m 4s\n",
            "467:\tlearn: 1.0190133\ttotal: 23m 45s\tremaining: 27m\n",
            "468:\tlearn: 1.0189034\ttotal: 23m 48s\tremaining: 26m 57s\n",
            "469:\tlearn: 1.0187722\ttotal: 23m 51s\tremaining: 26m 54s\n",
            "470:\tlearn: 1.0185905\ttotal: 23m 54s\tremaining: 26m 51s\n",
            "471:\tlearn: 1.0185218\ttotal: 23m 57s\tremaining: 26m 48s\n",
            "472:\tlearn: 1.0182423\ttotal: 24m\tremaining: 26m 45s\n",
            "473:\tlearn: 1.0181233\ttotal: 24m 3s\tremaining: 26m 42s\n",
            "474:\tlearn: 1.0179302\ttotal: 24m 6s\tremaining: 26m 39s\n",
            "475:\tlearn: 1.0177738\ttotal: 24m 9s\tremaining: 26m 35s\n",
            "476:\tlearn: 1.0175801\ttotal: 24m 12s\tremaining: 26m 32s\n",
            "477:\tlearn: 1.0174203\ttotal: 24m 15s\tremaining: 26m 29s\n",
            "478:\tlearn: 1.0172606\ttotal: 24m 18s\tremaining: 26m 26s\n",
            "479:\tlearn: 1.0171687\ttotal: 24m 21s\tremaining: 26m 23s\n",
            "480:\tlearn: 1.0170394\ttotal: 24m 24s\tremaining: 26m 20s\n",
            "481:\tlearn: 1.0168244\ttotal: 24m 27s\tremaining: 26m 17s\n",
            "482:\tlearn: 1.0166946\ttotal: 24m 30s\tremaining: 26m 14s\n",
            "483:\tlearn: 1.0164840\ttotal: 24m 33s\tremaining: 26m 11s\n",
            "484:\tlearn: 1.0163558\ttotal: 24m 36s\tremaining: 26m 8s\n",
            "485:\tlearn: 1.0162250\ttotal: 24m 39s\tremaining: 26m 5s\n",
            "486:\tlearn: 1.0161229\ttotal: 24m 42s\tremaining: 26m 1s\n",
            "487:\tlearn: 1.0159874\ttotal: 24m 45s\tremaining: 25m 59s\n",
            "488:\tlearn: 1.0158783\ttotal: 24m 49s\tremaining: 25m 56s\n",
            "489:\tlearn: 1.0157730\ttotal: 24m 52s\tremaining: 25m 52s\n",
            "490:\tlearn: 1.0156048\ttotal: 24m 55s\tremaining: 25m 50s\n",
            "491:\tlearn: 1.0155119\ttotal: 24m 58s\tremaining: 25m 47s\n",
            "492:\tlearn: 1.0153948\ttotal: 25m 1s\tremaining: 25m 44s\n",
            "493:\tlearn: 1.0152360\ttotal: 25m 4s\tremaining: 25m 40s\n",
            "494:\tlearn: 1.0150387\ttotal: 25m 7s\tremaining: 25m 37s\n",
            "495:\tlearn: 1.0148864\ttotal: 25m 10s\tremaining: 25m 34s\n",
            "496:\tlearn: 1.0148152\ttotal: 25m 13s\tremaining: 25m 31s\n",
            "497:\tlearn: 1.0146574\ttotal: 25m 16s\tremaining: 25m 28s\n",
            "498:\tlearn: 1.0146005\ttotal: 25m 19s\tremaining: 25m 25s\n",
            "499:\tlearn: 1.0144506\ttotal: 25m 22s\tremaining: 25m 22s\n",
            "500:\tlearn: 1.0142923\ttotal: 25m 26s\tremaining: 25m 20s\n",
            "501:\tlearn: 1.0142155\ttotal: 25m 29s\tremaining: 25m 17s\n",
            "502:\tlearn: 1.0140693\ttotal: 25m 32s\tremaining: 25m 14s\n",
            "503:\tlearn: 1.0140118\ttotal: 25m 35s\tremaining: 25m 11s\n",
            "504:\tlearn: 1.0138765\ttotal: 25m 39s\tremaining: 25m 8s\n",
            "505:\tlearn: 1.0137168\ttotal: 25m 42s\tremaining: 25m 5s\n",
            "506:\tlearn: 1.0136456\ttotal: 25m 45s\tremaining: 25m 2s\n",
            "507:\tlearn: 1.0135343\ttotal: 25m 48s\tremaining: 24m 59s\n",
            "508:\tlearn: 1.0133961\ttotal: 25m 51s\tremaining: 24m 56s\n",
            "509:\tlearn: 1.0132588\ttotal: 25m 54s\tremaining: 24m 53s\n",
            "510:\tlearn: 1.0131719\ttotal: 25m 57s\tremaining: 24m 50s\n",
            "511:\tlearn: 1.0130663\ttotal: 26m\tremaining: 24m 47s\n",
            "512:\tlearn: 1.0129017\ttotal: 26m 4s\tremaining: 24m 45s\n",
            "513:\tlearn: 1.0128286\ttotal: 26m 7s\tremaining: 24m 42s\n",
            "514:\tlearn: 1.0127036\ttotal: 26m 10s\tremaining: 24m 38s\n",
            "515:\tlearn: 1.0126200\ttotal: 26m 13s\tremaining: 24m 35s\n",
            "516:\tlearn: 1.0125253\ttotal: 26m 16s\tremaining: 24m 32s\n",
            "517:\tlearn: 1.0123790\ttotal: 26m 19s\tremaining: 24m 29s\n",
            "518:\tlearn: 1.0123137\ttotal: 26m 22s\tremaining: 24m 26s\n",
            "519:\tlearn: 1.0122309\ttotal: 26m 25s\tremaining: 24m 23s\n",
            "520:\tlearn: 1.0120713\ttotal: 26m 28s\tremaining: 24m 20s\n",
            "521:\tlearn: 1.0118831\ttotal: 26m 31s\tremaining: 24m 17s\n",
            "522:\tlearn: 1.0117515\ttotal: 26m 34s\tremaining: 24m 14s\n",
            "523:\tlearn: 1.0115298\ttotal: 26m 37s\tremaining: 24m 10s\n",
            "524:\tlearn: 1.0113741\ttotal: 26m 39s\tremaining: 24m 7s\n",
            "525:\tlearn: 1.0112470\ttotal: 26m 42s\tremaining: 24m 4s\n",
            "526:\tlearn: 1.0111303\ttotal: 26m 45s\tremaining: 24m\n",
            "527:\tlearn: 1.0110220\ttotal: 26m 48s\tremaining: 23m 57s\n",
            "528:\tlearn: 1.0109302\ttotal: 26m 50s\tremaining: 23m 54s\n",
            "529:\tlearn: 1.0107562\ttotal: 26m 53s\tremaining: 23m 50s\n",
            "530:\tlearn: 1.0106406\ttotal: 26m 56s\tremaining: 23m 47s\n",
            "531:\tlearn: 1.0104991\ttotal: 26m 59s\tremaining: 23m 44s\n",
            "532:\tlearn: 1.0103913\ttotal: 27m 1s\tremaining: 23m 40s\n",
            "533:\tlearn: 1.0102682\ttotal: 27m 4s\tremaining: 23m 37s\n",
            "534:\tlearn: 1.0101577\ttotal: 27m 7s\tremaining: 23m 34s\n",
            "535:\tlearn: 1.0100864\ttotal: 27m 9s\tremaining: 23m 30s\n",
            "536:\tlearn: 1.0099824\ttotal: 27m 12s\tremaining: 23m 27s\n",
            "537:\tlearn: 1.0098830\ttotal: 27m 15s\tremaining: 23m 24s\n",
            "538:\tlearn: 1.0097424\ttotal: 27m 17s\tremaining: 23m 20s\n",
            "539:\tlearn: 1.0096149\ttotal: 27m 20s\tremaining: 23m 17s\n",
            "540:\tlearn: 1.0095085\ttotal: 27m 23s\tremaining: 23m 14s\n",
            "541:\tlearn: 1.0092174\ttotal: 27m 26s\tremaining: 23m 10s\n",
            "542:\tlearn: 1.0090897\ttotal: 27m 28s\tremaining: 23m 7s\n",
            "543:\tlearn: 1.0089550\ttotal: 27m 31s\tremaining: 23m 4s\n",
            "544:\tlearn: 1.0087738\ttotal: 27m 34s\tremaining: 23m 1s\n",
            "545:\tlearn: 1.0086632\ttotal: 27m 37s\tremaining: 22m 57s\n",
            "546:\tlearn: 1.0085236\ttotal: 27m 39s\tremaining: 22m 54s\n",
            "547:\tlearn: 1.0084438\ttotal: 27m 42s\tremaining: 22m 51s\n",
            "548:\tlearn: 1.0083738\ttotal: 27m 45s\tremaining: 22m 47s\n",
            "549:\tlearn: 1.0082519\ttotal: 27m 47s\tremaining: 22m 44s\n",
            "550:\tlearn: 1.0081185\ttotal: 27m 50s\tremaining: 22m 41s\n",
            "551:\tlearn: 1.0080247\ttotal: 27m 53s\tremaining: 22m 37s\n",
            "552:\tlearn: 1.0079137\ttotal: 27m 55s\tremaining: 22m 34s\n",
            "553:\tlearn: 1.0077996\ttotal: 27m 58s\tremaining: 22m 31s\n",
            "554:\tlearn: 1.0076504\ttotal: 28m 1s\tremaining: 22m 28s\n",
            "555:\tlearn: 1.0075557\ttotal: 28m 3s\tremaining: 22m 24s\n",
            "556:\tlearn: 1.0074862\ttotal: 28m 6s\tremaining: 22m 21s\n",
            "557:\tlearn: 1.0073313\ttotal: 28m 9s\tremaining: 22m 18s\n",
            "558:\tlearn: 1.0072317\ttotal: 28m 12s\tremaining: 22m 14s\n",
            "559:\tlearn: 1.0070497\ttotal: 28m 14s\tremaining: 22m 11s\n",
            "560:\tlearn: 1.0068994\ttotal: 28m 17s\tremaining: 22m 8s\n",
            "561:\tlearn: 1.0068250\ttotal: 28m 20s\tremaining: 22m 5s\n",
            "562:\tlearn: 1.0067299\ttotal: 28m 23s\tremaining: 22m 1s\n",
            "563:\tlearn: 1.0065827\ttotal: 28m 25s\tremaining: 21m 58s\n",
            "564:\tlearn: 1.0064346\ttotal: 28m 28s\tremaining: 21m 55s\n",
            "565:\tlearn: 1.0063184\ttotal: 28m 31s\tremaining: 21m 52s\n",
            "566:\tlearn: 1.0062437\ttotal: 28m 33s\tremaining: 21m 48s\n",
            "567:\tlearn: 1.0062298\ttotal: 28m 36s\tremaining: 21m 45s\n",
            "568:\tlearn: 1.0061749\ttotal: 28m 39s\tremaining: 21m 42s\n",
            "569:\tlearn: 1.0061129\ttotal: 28m 41s\tremaining: 21m 38s\n",
            "570:\tlearn: 1.0060127\ttotal: 28m 44s\tremaining: 21m 35s\n",
            "571:\tlearn: 1.0058703\ttotal: 28m 47s\tremaining: 21m 32s\n",
            "572:\tlearn: 1.0057513\ttotal: 28m 49s\tremaining: 21m 29s\n",
            "573:\tlearn: 1.0056181\ttotal: 28m 52s\tremaining: 21m 25s\n",
            "574:\tlearn: 1.0055799\ttotal: 28m 55s\tremaining: 21m 22s\n",
            "575:\tlearn: 1.0054529\ttotal: 28m 58s\tremaining: 21m 19s\n",
            "576:\tlearn: 1.0053184\ttotal: 29m\tremaining: 21m 16s\n",
            "577:\tlearn: 1.0051933\ttotal: 29m 3s\tremaining: 21m 12s\n",
            "578:\tlearn: 1.0051180\ttotal: 29m 6s\tremaining: 21m 9s\n",
            "579:\tlearn: 1.0050209\ttotal: 29m 8s\tremaining: 21m 6s\n",
            "580:\tlearn: 1.0049575\ttotal: 29m 11s\tremaining: 21m 3s\n",
            "581:\tlearn: 1.0048403\ttotal: 29m 14s\tremaining: 20m 59s\n",
            "582:\tlearn: 1.0046036\ttotal: 29m 16s\tremaining: 20m 56s\n",
            "583:\tlearn: 1.0044905\ttotal: 29m 19s\tremaining: 20m 53s\n",
            "584:\tlearn: 1.0043607\ttotal: 29m 22s\tremaining: 20m 50s\n",
            "585:\tlearn: 1.0042289\ttotal: 29m 25s\tremaining: 20m 47s\n",
            "586:\tlearn: 1.0040741\ttotal: 29m 27s\tremaining: 20m 43s\n",
            "587:\tlearn: 1.0038838\ttotal: 29m 30s\tremaining: 20m 40s\n",
            "588:\tlearn: 1.0037852\ttotal: 29m 33s\tremaining: 20m 37s\n",
            "589:\tlearn: 1.0036282\ttotal: 29m 35s\tremaining: 20m 34s\n",
            "590:\tlearn: 1.0034776\ttotal: 29m 38s\tremaining: 20m 30s\n",
            "591:\tlearn: 1.0034517\ttotal: 29m 41s\tremaining: 20m 27s\n",
            "592:\tlearn: 1.0033820\ttotal: 29m 44s\tremaining: 20m 24s\n",
            "593:\tlearn: 1.0033078\ttotal: 29m 47s\tremaining: 20m 21s\n",
            "594:\tlearn: 1.0032472\ttotal: 29m 49s\tremaining: 20m 18s\n",
            "595:\tlearn: 1.0031299\ttotal: 29m 52s\tremaining: 20m 15s\n",
            "596:\tlearn: 1.0030147\ttotal: 29m 55s\tremaining: 20m 11s\n",
            "597:\tlearn: 1.0029002\ttotal: 29m 57s\tremaining: 20m 8s\n",
            "598:\tlearn: 1.0027719\ttotal: 30m\tremaining: 20m 5s\n",
            "599:\tlearn: 1.0027236\ttotal: 30m 3s\tremaining: 20m 2s\n",
            "600:\tlearn: 1.0026315\ttotal: 30m 6s\tremaining: 19m 59s\n",
            "601:\tlearn: 1.0025293\ttotal: 30m 8s\tremaining: 19m 55s\n",
            "602:\tlearn: 1.0023899\ttotal: 30m 11s\tremaining: 19m 52s\n",
            "603:\tlearn: 1.0022858\ttotal: 30m 14s\tremaining: 19m 49s\n",
            "604:\tlearn: 1.0022249\ttotal: 30m 16s\tremaining: 19m 46s\n",
            "605:\tlearn: 1.0021676\ttotal: 30m 19s\tremaining: 19m 43s\n",
            "606:\tlearn: 1.0020755\ttotal: 30m 22s\tremaining: 19m 39s\n",
            "607:\tlearn: 1.0019229\ttotal: 30m 25s\tremaining: 19m 36s\n",
            "608:\tlearn: 1.0018379\ttotal: 30m 27s\tremaining: 19m 33s\n",
            "609:\tlearn: 1.0017434\ttotal: 30m 30s\tremaining: 19m 30s\n",
            "610:\tlearn: 1.0016131\ttotal: 30m 33s\tremaining: 19m 27s\n",
            "611:\tlearn: 1.0015194\ttotal: 30m 36s\tremaining: 19m 24s\n",
            "612:\tlearn: 1.0014561\ttotal: 30m 39s\tremaining: 19m 21s\n",
            "613:\tlearn: 1.0013310\ttotal: 30m 42s\tremaining: 19m 18s\n",
            "614:\tlearn: 1.0012213\ttotal: 30m 45s\tremaining: 19m 15s\n",
            "615:\tlearn: 1.0009378\ttotal: 30m 48s\tremaining: 19m 12s\n",
            "616:\tlearn: 1.0008114\ttotal: 30m 51s\tremaining: 19m 9s\n",
            "617:\tlearn: 1.0006453\ttotal: 30m 54s\tremaining: 19m 6s\n",
            "618:\tlearn: 1.0006113\ttotal: 30m 57s\tremaining: 19m 3s\n",
            "619:\tlearn: 1.0005140\ttotal: 31m\tremaining: 19m\n",
            "620:\tlearn: 1.0003744\ttotal: 31m 2s\tremaining: 18m 56s\n",
            "621:\tlearn: 1.0002639\ttotal: 31m 5s\tremaining: 18m 53s\n",
            "622:\tlearn: 1.0001471\ttotal: 31m 8s\tremaining: 18m 50s\n",
            "623:\tlearn: 1.0000733\ttotal: 31m 12s\tremaining: 18m 48s\n",
            "624:\tlearn: 0.9999106\ttotal: 31m 15s\tremaining: 18m 45s\n",
            "625:\tlearn: 0.9998674\ttotal: 31m 18s\tremaining: 18m 42s\n",
            "626:\tlearn: 0.9997351\ttotal: 31m 21s\tremaining: 18m 39s\n",
            "627:\tlearn: 0.9996170\ttotal: 31m 24s\tremaining: 18m 36s\n",
            "628:\tlearn: 0.9995565\ttotal: 31m 27s\tremaining: 18m 33s\n",
            "629:\tlearn: 0.9994431\ttotal: 31m 30s\tremaining: 18m 30s\n",
            "630:\tlearn: 0.9993939\ttotal: 31m 33s\tremaining: 18m 27s\n",
            "631:\tlearn: 0.9993027\ttotal: 31m 37s\tremaining: 18m 24s\n",
            "632:\tlearn: 0.9991714\ttotal: 31m 40s\tremaining: 18m 21s\n",
            "633:\tlearn: 0.9990378\ttotal: 31m 43s\tremaining: 18m 18s\n",
            "634:\tlearn: 0.9989252\ttotal: 31m 46s\tremaining: 18m 15s\n",
            "635:\tlearn: 0.9988029\ttotal: 31m 49s\tremaining: 18m 12s\n",
            "636:\tlearn: 0.9986983\ttotal: 31m 52s\tremaining: 18m 9s\n",
            "637:\tlearn: 0.9986083\ttotal: 31m 55s\tremaining: 18m 7s\n",
            "638:\tlearn: 0.9985552\ttotal: 31m 58s\tremaining: 18m 4s\n",
            "639:\tlearn: 0.9985112\ttotal: 32m 1s\tremaining: 18m\n",
            "640:\tlearn: 0.9984729\ttotal: 32m 4s\tremaining: 17m 57s\n",
            "641:\tlearn: 0.9983443\ttotal: 32m 7s\tremaining: 17m 54s\n",
            "642:\tlearn: 0.9982028\ttotal: 32m 10s\tremaining: 17m 51s\n",
            "643:\tlearn: 0.9980888\ttotal: 32m 13s\tremaining: 17m 49s\n",
            "644:\tlearn: 0.9979828\ttotal: 32m 17s\tremaining: 17m 46s\n",
            "645:\tlearn: 0.9978085\ttotal: 32m 20s\tremaining: 17m 43s\n",
            "646:\tlearn: 0.9977031\ttotal: 32m 23s\tremaining: 17m 40s\n",
            "647:\tlearn: 0.9976288\ttotal: 32m 26s\tremaining: 17m 37s\n",
            "648:\tlearn: 0.9975288\ttotal: 32m 28s\tremaining: 17m 34s\n",
            "649:\tlearn: 0.9974674\ttotal: 32m 31s\tremaining: 17m 30s\n",
            "650:\tlearn: 0.9973770\ttotal: 32m 34s\tremaining: 17m 27s\n",
            "651:\tlearn: 0.9972676\ttotal: 32m 37s\tremaining: 17m 24s\n",
            "652:\tlearn: 0.9971505\ttotal: 32m 40s\tremaining: 17m 21s\n",
            "653:\tlearn: 0.9970625\ttotal: 32m 43s\tremaining: 17m 18s\n",
            "654:\tlearn: 0.9970321\ttotal: 32m 45s\tremaining: 17m 15s\n",
            "655:\tlearn: 0.9969259\ttotal: 32m 48s\tremaining: 17m 12s\n",
            "656:\tlearn: 0.9968450\ttotal: 32m 51s\tremaining: 17m 9s\n",
            "657:\tlearn: 0.9968147\ttotal: 32m 53s\tremaining: 17m 5s\n",
            "658:\tlearn: 0.9967544\ttotal: 32m 56s\tremaining: 17m 2s\n",
            "659:\tlearn: 0.9966613\ttotal: 32m 59s\tremaining: 16m 59s\n",
            "660:\tlearn: 0.9965646\ttotal: 33m 1s\tremaining: 16m 56s\n",
            "661:\tlearn: 0.9964885\ttotal: 33m 4s\tremaining: 16m 53s\n",
            "662:\tlearn: 0.9962671\ttotal: 33m 7s\tremaining: 16m 50s\n",
            "663:\tlearn: 0.9961718\ttotal: 33m 9s\tremaining: 16m 46s\n",
            "664:\tlearn: 0.9961083\ttotal: 33m 12s\tremaining: 16m 43s\n",
            "665:\tlearn: 0.9960239\ttotal: 33m 14s\tremaining: 16m 40s\n",
            "666:\tlearn: 0.9959513\ttotal: 33m 17s\tremaining: 16m 37s\n",
            "667:\tlearn: 0.9958637\ttotal: 33m 20s\tremaining: 16m 34s\n",
            "668:\tlearn: 0.9957634\ttotal: 33m 22s\tremaining: 16m 30s\n",
            "669:\tlearn: 0.9956337\ttotal: 33m 25s\tremaining: 16m 27s\n",
            "670:\tlearn: 0.9955191\ttotal: 33m 28s\tremaining: 16m 24s\n",
            "671:\tlearn: 0.9954313\ttotal: 33m 30s\tremaining: 16m 21s\n",
            "672:\tlearn: 0.9953381\ttotal: 33m 33s\tremaining: 16m 18s\n",
            "673:\tlearn: 0.9952742\ttotal: 33m 36s\tremaining: 16m 15s\n",
            "674:\tlearn: 0.9952108\ttotal: 33m 38s\tremaining: 16m 12s\n",
            "675:\tlearn: 0.9951122\ttotal: 33m 41s\tremaining: 16m 8s\n",
            "676:\tlearn: 0.9949995\ttotal: 33m 44s\tremaining: 16m 5s\n",
            "677:\tlearn: 0.9949222\ttotal: 33m 46s\tremaining: 16m 2s\n",
            "678:\tlearn: 0.9948178\ttotal: 33m 49s\tremaining: 15m 59s\n",
            "679:\tlearn: 0.9947717\ttotal: 33m 52s\tremaining: 15m 56s\n",
            "680:\tlearn: 0.9946970\ttotal: 33m 55s\tremaining: 15m 53s\n",
            "681:\tlearn: 0.9946625\ttotal: 33m 57s\tremaining: 15m 50s\n",
            "682:\tlearn: 0.9945471\ttotal: 34m\tremaining: 15m 47s\n",
            "683:\tlearn: 0.9945082\ttotal: 34m 3s\tremaining: 15m 44s\n",
            "684:\tlearn: 0.9944337\ttotal: 34m 5s\tremaining: 15m 40s\n",
            "685:\tlearn: 0.9943484\ttotal: 34m 8s\tremaining: 15m 37s\n",
            "686:\tlearn: 0.9942464\ttotal: 34m 11s\tremaining: 15m 34s\n",
            "687:\tlearn: 0.9941454\ttotal: 34m 14s\tremaining: 15m 31s\n",
            "688:\tlearn: 0.9939734\ttotal: 34m 17s\tremaining: 15m 28s\n",
            "689:\tlearn: 0.9939080\ttotal: 34m 20s\tremaining: 15m 25s\n",
            "690:\tlearn: 0.9938007\ttotal: 34m 23s\tremaining: 15m 22s\n",
            "691:\tlearn: 0.9937089\ttotal: 34m 26s\tremaining: 15m 19s\n",
            "692:\tlearn: 0.9936158\ttotal: 34m 29s\tremaining: 15m 16s\n",
            "693:\tlearn: 0.9935473\ttotal: 34m 32s\tremaining: 15m 13s\n",
            "694:\tlearn: 0.9934998\ttotal: 34m 35s\tremaining: 15m 10s\n",
            "695:\tlearn: 0.9934483\ttotal: 34m 38s\tremaining: 15m 7s\n",
            "696:\tlearn: 0.9934073\ttotal: 34m 40s\tremaining: 15m 4s\n",
            "697:\tlearn: 0.9932896\ttotal: 34m 43s\tremaining: 15m 1s\n",
            "698:\tlearn: 0.9931696\ttotal: 34m 46s\tremaining: 14m 58s\n",
            "699:\tlearn: 0.9931018\ttotal: 34m 49s\tremaining: 14m 55s\n",
            "700:\tlearn: 0.9929061\ttotal: 34m 52s\tremaining: 14m 52s\n",
            "701:\tlearn: 0.9928806\ttotal: 34m 55s\tremaining: 14m 49s\n",
            "702:\tlearn: 0.9927550\ttotal: 34m 58s\tremaining: 14m 46s\n",
            "703:\tlearn: 0.9926689\ttotal: 35m\tremaining: 14m 43s\n",
            "704:\tlearn: 0.9926344\ttotal: 35m 3s\tremaining: 14m 40s\n",
            "705:\tlearn: 0.9924614\ttotal: 35m 6s\tremaining: 14m 37s\n",
            "706:\tlearn: 0.9923791\ttotal: 35m 9s\tremaining: 14m 34s\n",
            "707:\tlearn: 0.9923018\ttotal: 35m 12s\tremaining: 14m 31s\n",
            "708:\tlearn: 0.9921847\ttotal: 35m 14s\tremaining: 14m 28s\n",
            "709:\tlearn: 0.9921081\ttotal: 35m 17s\tremaining: 14m 24s\n",
            "710:\tlearn: 0.9920150\ttotal: 35m 20s\tremaining: 14m 21s\n",
            "711:\tlearn: 0.9919082\ttotal: 35m 23s\tremaining: 14m 18s\n",
            "712:\tlearn: 0.9918676\ttotal: 35m 26s\tremaining: 14m 15s\n",
            "713:\tlearn: 0.9917446\ttotal: 35m 29s\tremaining: 14m 12s\n",
            "714:\tlearn: 0.9916220\ttotal: 35m 32s\tremaining: 14m 9s\n",
            "715:\tlearn: 0.9915517\ttotal: 35m 34s\tremaining: 14m 6s\n",
            "716:\tlearn: 0.9915020\ttotal: 35m 37s\tremaining: 14m 3s\n",
            "717:\tlearn: 0.9913955\ttotal: 35m 40s\tremaining: 14m\n",
            "718:\tlearn: 0.9913413\ttotal: 35m 43s\tremaining: 13m 57s\n",
            "719:\tlearn: 0.9912591\ttotal: 35m 46s\tremaining: 13m 54s\n",
            "720:\tlearn: 0.9911909\ttotal: 35m 49s\tremaining: 13m 51s\n",
            "721:\tlearn: 0.9911151\ttotal: 35m 52s\tremaining: 13m 48s\n",
            "722:\tlearn: 0.9910812\ttotal: 35m 54s\tremaining: 13m 45s\n",
            "723:\tlearn: 0.9910261\ttotal: 35m 57s\tremaining: 13m 42s\n",
            "724:\tlearn: 0.9909874\ttotal: 36m\tremaining: 13m 39s\n",
            "725:\tlearn: 0.9908825\ttotal: 36m 3s\tremaining: 13m 36s\n",
            "726:\tlearn: 0.9908421\ttotal: 36m 6s\tremaining: 13m 33s\n",
            "727:\tlearn: 0.9907614\ttotal: 36m 8s\tremaining: 13m 30s\n",
            "728:\tlearn: 0.9906648\ttotal: 36m 11s\tremaining: 13m 27s\n",
            "729:\tlearn: 0.9905425\ttotal: 36m 14s\tremaining: 13m 24s\n",
            "730:\tlearn: 0.9904551\ttotal: 36m 17s\tremaining: 13m 21s\n",
            "731:\tlearn: 0.9903619\ttotal: 36m 20s\tremaining: 13m 18s\n",
            "732:\tlearn: 0.9902571\ttotal: 36m 23s\tremaining: 13m 15s\n",
            "733:\tlearn: 0.9901804\ttotal: 36m 26s\tremaining: 13m 12s\n",
            "734:\tlearn: 0.9901318\ttotal: 36m 29s\tremaining: 13m 9s\n",
            "735:\tlearn: 0.9900262\ttotal: 36m 31s\tremaining: 13m 6s\n",
            "736:\tlearn: 0.9898576\ttotal: 36m 34s\tremaining: 13m 3s\n",
            "737:\tlearn: 0.9897758\ttotal: 36m 37s\tremaining: 13m\n",
            "738:\tlearn: 0.9897009\ttotal: 36m 40s\tremaining: 12m 57s\n",
            "739:\tlearn: 0.9896312\ttotal: 36m 43s\tremaining: 12m 54s\n",
            "740:\tlearn: 0.9895202\ttotal: 36m 46s\tremaining: 12m 51s\n",
            "741:\tlearn: 0.9893997\ttotal: 36m 49s\tremaining: 12m 48s\n",
            "742:\tlearn: 0.9892809\ttotal: 36m 52s\tremaining: 12m 45s\n",
            "743:\tlearn: 0.9891389\ttotal: 36m 55s\tremaining: 12m 42s\n",
            "744:\tlearn: 0.9890421\ttotal: 36m 58s\tremaining: 12m 39s\n",
            "745:\tlearn: 0.9889740\ttotal: 37m 2s\tremaining: 12m 36s\n",
            "746:\tlearn: 0.9889169\ttotal: 37m 5s\tremaining: 12m 33s\n",
            "747:\tlearn: 0.9887818\ttotal: 37m 8s\tremaining: 12m 30s\n",
            "748:\tlearn: 0.9887109\ttotal: 37m 10s\tremaining: 12m 27s\n",
            "749:\tlearn: 0.9886255\ttotal: 37m 13s\tremaining: 12m 24s\n",
            "750:\tlearn: 0.9885326\ttotal: 37m 16s\tremaining: 12m 21s\n",
            "751:\tlearn: 0.9884812\ttotal: 37m 19s\tremaining: 12m 18s\n",
            "752:\tlearn: 0.9884108\ttotal: 37m 22s\tremaining: 12m 15s\n",
            "753:\tlearn: 0.9883729\ttotal: 37m 24s\tremaining: 12m 12s\n",
            "754:\tlearn: 0.9882518\ttotal: 37m 28s\tremaining: 12m 9s\n",
            "755:\tlearn: 0.9882179\ttotal: 37m 31s\tremaining: 12m 6s\n",
            "756:\tlearn: 0.9881552\ttotal: 37m 35s\tremaining: 12m 3s\n",
            "757:\tlearn: 0.9880820\ttotal: 37m 38s\tremaining: 12m 1s\n",
            "758:\tlearn: 0.9880238\ttotal: 37m 41s\tremaining: 11m 58s\n",
            "759:\tlearn: 0.9878907\ttotal: 37m 45s\tremaining: 11m 55s\n",
            "760:\tlearn: 0.9878014\ttotal: 37m 49s\tremaining: 11m 52s\n",
            "761:\tlearn: 0.9877119\ttotal: 37m 52s\tremaining: 11m 49s\n",
            "762:\tlearn: 0.9876331\ttotal: 37m 55s\tremaining: 11m 46s\n",
            "763:\tlearn: 0.9876088\ttotal: 37m 58s\tremaining: 11m 43s\n",
            "764:\tlearn: 0.9875061\ttotal: 38m 1s\tremaining: 11m 40s\n",
            "765:\tlearn: 0.9874551\ttotal: 38m 4s\tremaining: 11m 37s\n",
            "766:\tlearn: 0.9873885\ttotal: 38m 8s\tremaining: 11m 35s\n",
            "767:\tlearn: 0.9873031\ttotal: 38m 11s\tremaining: 11m 32s\n",
            "768:\tlearn: 0.9871043\ttotal: 38m 14s\tremaining: 11m 29s\n",
            "769:\tlearn: 0.9870274\ttotal: 38m 17s\tremaining: 11m 26s\n",
            "770:\tlearn: 0.9869348\ttotal: 38m 20s\tremaining: 11m 23s\n",
            "771:\tlearn: 0.9868547\ttotal: 38m 23s\tremaining: 11m 20s\n",
            "772:\tlearn: 0.9867533\ttotal: 38m 26s\tremaining: 11m 17s\n",
            "773:\tlearn: 0.9866170\ttotal: 38m 29s\tremaining: 11m 14s\n",
            "774:\tlearn: 0.9865372\ttotal: 38m 32s\tremaining: 11m 11s\n",
            "775:\tlearn: 0.9864005\ttotal: 38m 35s\tremaining: 11m 8s\n",
            "776:\tlearn: 0.9863640\ttotal: 38m 37s\tremaining: 11m 5s\n",
            "777:\tlearn: 0.9863203\ttotal: 38m 40s\tremaining: 11m 2s\n",
            "778:\tlearn: 0.9861816\ttotal: 38m 43s\tremaining: 10m 59s\n",
            "779:\tlearn: 0.9861532\ttotal: 38m 45s\tremaining: 10m 55s\n",
            "780:\tlearn: 0.9860084\ttotal: 38m 48s\tremaining: 10m 52s\n",
            "781:\tlearn: 0.9859274\ttotal: 38m 50s\tremaining: 10m 49s\n",
            "782:\tlearn: 0.9858256\ttotal: 38m 53s\tremaining: 10m 46s\n",
            "783:\tlearn: 0.9857576\ttotal: 38m 56s\tremaining: 10m 43s\n",
            "784:\tlearn: 0.9856369\ttotal: 38m 59s\tremaining: 10m 40s\n",
            "785:\tlearn: 0.9855672\ttotal: 39m 1s\tremaining: 10m 37s\n",
            "786:\tlearn: 0.9855418\ttotal: 39m 4s\tremaining: 10m 34s\n",
            "787:\tlearn: 0.9854582\ttotal: 39m 7s\tremaining: 10m 31s\n",
            "788:\tlearn: 0.9853914\ttotal: 39m 9s\tremaining: 10m 28s\n",
            "789:\tlearn: 0.9853406\ttotal: 39m 12s\tremaining: 10m 25s\n",
            "790:\tlearn: 0.9852372\ttotal: 39m 15s\tremaining: 10m 22s\n",
            "791:\tlearn: 0.9852081\ttotal: 39m 17s\tremaining: 10m 19s\n",
            "792:\tlearn: 0.9850864\ttotal: 39m 20s\tremaining: 10m 16s\n",
            "793:\tlearn: 0.9850187\ttotal: 39m 23s\tremaining: 10m 13s\n",
            "794:\tlearn: 0.9849474\ttotal: 39m 25s\tremaining: 10m 10s\n",
            "795:\tlearn: 0.9849314\ttotal: 39m 28s\tremaining: 10m 6s\n",
            "796:\tlearn: 0.9849148\ttotal: 39m 31s\tremaining: 10m 3s\n",
            "797:\tlearn: 0.9848491\ttotal: 39m 33s\tremaining: 10m\n",
            "798:\tlearn: 0.9847976\ttotal: 39m 36s\tremaining: 9m 57s\n",
            "799:\tlearn: 0.9847177\ttotal: 39m 39s\tremaining: 9m 54s\n",
            "800:\tlearn: 0.9846185\ttotal: 39m 41s\tremaining: 9m 51s\n",
            "801:\tlearn: 0.9845298\ttotal: 39m 44s\tremaining: 9m 48s\n",
            "802:\tlearn: 0.9844679\ttotal: 39m 47s\tremaining: 9m 45s\n",
            "803:\tlearn: 0.9843871\ttotal: 39m 49s\tremaining: 9m 42s\n",
            "804:\tlearn: 0.9842622\ttotal: 39m 52s\tremaining: 9m 39s\n",
            "805:\tlearn: 0.9841840\ttotal: 39m 55s\tremaining: 9m 36s\n",
            "806:\tlearn: 0.9841327\ttotal: 39m 57s\tremaining: 9m 33s\n",
            "807:\tlearn: 0.9840828\ttotal: 40m\tremaining: 9m 30s\n",
            "808:\tlearn: 0.9840116\ttotal: 40m 3s\tremaining: 9m 27s\n",
            "809:\tlearn: 0.9839495\ttotal: 40m 5s\tremaining: 9m 24s\n",
            "810:\tlearn: 0.9838152\ttotal: 40m 8s\tremaining: 9m 21s\n",
            "811:\tlearn: 0.9837585\ttotal: 40m 11s\tremaining: 9m 18s\n",
            "812:\tlearn: 0.9836815\ttotal: 40m 13s\tremaining: 9m 15s\n",
            "813:\tlearn: 0.9835970\ttotal: 40m 16s\tremaining: 9m 12s\n",
            "814:\tlearn: 0.9835375\ttotal: 40m 19s\tremaining: 9m 9s\n",
            "815:\tlearn: 0.9835013\ttotal: 40m 21s\tremaining: 9m 6s\n",
            "816:\tlearn: 0.9834518\ttotal: 40m 24s\tremaining: 9m 3s\n",
            "817:\tlearn: 0.9834160\ttotal: 40m 27s\tremaining: 9m\n",
            "818:\tlearn: 0.9833473\ttotal: 40m 29s\tremaining: 8m 56s\n",
            "819:\tlearn: 0.9833051\ttotal: 40m 32s\tremaining: 8m 54s\n",
            "820:\tlearn: 0.9832399\ttotal: 40m 35s\tremaining: 8m 51s\n",
            "821:\tlearn: 0.9832204\ttotal: 40m 38s\tremaining: 8m 48s\n",
            "822:\tlearn: 0.9831567\ttotal: 40m 41s\tremaining: 8m 45s\n",
            "823:\tlearn: 0.9830982\ttotal: 40m 44s\tremaining: 8m 42s\n",
            "824:\tlearn: 0.9830077\ttotal: 40m 46s\tremaining: 8m 39s\n",
            "825:\tlearn: 0.9829915\ttotal: 40m 49s\tremaining: 8m 36s\n",
            "826:\tlearn: 0.9828930\ttotal: 40m 52s\tremaining: 8m 33s\n",
            "827:\tlearn: 0.9828851\ttotal: 40m 54s\tremaining: 8m 29s\n",
            "828:\tlearn: 0.9828565\ttotal: 40m 57s\tremaining: 8m 26s\n",
            "829:\tlearn: 0.9828175\ttotal: 41m\tremaining: 8m 23s\n",
            "830:\tlearn: 0.9827568\ttotal: 41m 2s\tremaining: 8m 20s\n",
            "831:\tlearn: 0.9827060\ttotal: 41m 5s\tremaining: 8m 17s\n",
            "832:\tlearn: 0.9826849\ttotal: 41m 8s\tremaining: 8m 14s\n",
            "833:\tlearn: 0.9826188\ttotal: 41m 10s\tremaining: 8m 11s\n",
            "834:\tlearn: 0.9825518\ttotal: 41m 13s\tremaining: 8m 8s\n",
            "835:\tlearn: 0.9825249\ttotal: 41m 16s\tremaining: 8m 5s\n",
            "836:\tlearn: 0.9824891\ttotal: 41m 18s\tremaining: 8m 2s\n",
            "837:\tlearn: 0.9824308\ttotal: 41m 21s\tremaining: 7m 59s\n",
            "838:\tlearn: 0.9823736\ttotal: 41m 24s\tremaining: 7m 56s\n",
            "839:\tlearn: 0.9823394\ttotal: 41m 26s\tremaining: 7m 53s\n",
            "840:\tlearn: 0.9823032\ttotal: 41m 29s\tremaining: 7m 50s\n",
            "841:\tlearn: 0.9822829\ttotal: 41m 32s\tremaining: 7m 47s\n",
            "842:\tlearn: 0.9822187\ttotal: 41m 34s\tremaining: 7m 44s\n",
            "843:\tlearn: 0.9821452\ttotal: 41m 37s\tremaining: 7m 41s\n",
            "844:\tlearn: 0.9820939\ttotal: 41m 40s\tremaining: 7m 38s\n",
            "845:\tlearn: 0.9820163\ttotal: 41m 42s\tremaining: 7m 35s\n",
            "846:\tlearn: 0.9819779\ttotal: 41m 45s\tremaining: 7m 32s\n",
            "847:\tlearn: 0.9819296\ttotal: 41m 48s\tremaining: 7m 29s\n",
            "848:\tlearn: 0.9817901\ttotal: 41m 51s\tremaining: 7m 26s\n",
            "849:\tlearn: 0.9816967\ttotal: 41m 53s\tremaining: 7m 23s\n",
            "850:\tlearn: 0.9816719\ttotal: 41m 56s\tremaining: 7m 20s\n",
            "851:\tlearn: 0.9816200\ttotal: 41m 59s\tremaining: 7m 17s\n",
            "852:\tlearn: 0.9815109\ttotal: 42m 1s\tremaining: 7m 14s\n",
            "853:\tlearn: 0.9814900\ttotal: 42m 4s\tremaining: 7m 11s\n",
            "854:\tlearn: 0.9814395\ttotal: 42m 7s\tremaining: 7m 8s\n",
            "855:\tlearn: 0.9813921\ttotal: 42m 9s\tremaining: 7m 5s\n",
            "856:\tlearn: 0.9813652\ttotal: 42m 12s\tremaining: 7m 2s\n",
            "857:\tlearn: 0.9813353\ttotal: 42m 15s\tremaining: 6m 59s\n",
            "858:\tlearn: 0.9812882\ttotal: 42m 17s\tremaining: 6m 56s\n",
            "859:\tlearn: 0.9812079\ttotal: 42m 20s\tremaining: 6m 53s\n",
            "860:\tlearn: 0.9810841\ttotal: 42m 23s\tremaining: 6m 50s\n",
            "861:\tlearn: 0.9810279\ttotal: 42m 25s\tremaining: 6m 47s\n",
            "862:\tlearn: 0.9810051\ttotal: 42m 28s\tremaining: 6m 44s\n",
            "863:\tlearn: 0.9809389\ttotal: 42m 31s\tremaining: 6m 41s\n",
            "864:\tlearn: 0.9808970\ttotal: 42m 33s\tremaining: 6m 38s\n",
            "865:\tlearn: 0.9808291\ttotal: 42m 36s\tremaining: 6m 35s\n",
            "866:\tlearn: 0.9807892\ttotal: 42m 38s\tremaining: 6m 32s\n",
            "867:\tlearn: 0.9807189\ttotal: 42m 41s\tremaining: 6m 29s\n",
            "868:\tlearn: 0.9807000\ttotal: 42m 44s\tremaining: 6m 26s\n",
            "869:\tlearn: 0.9806666\ttotal: 42m 46s\tremaining: 6m 23s\n",
            "870:\tlearn: 0.9805904\ttotal: 42m 49s\tremaining: 6m 20s\n",
            "871:\tlearn: 0.9805124\ttotal: 42m 52s\tremaining: 6m 17s\n",
            "872:\tlearn: 0.9804335\ttotal: 42m 54s\tremaining: 6m 14s\n",
            "873:\tlearn: 0.9802380\ttotal: 42m 57s\tremaining: 6m 11s\n",
            "874:\tlearn: 0.9801821\ttotal: 43m\tremaining: 6m 8s\n",
            "875:\tlearn: 0.9801024\ttotal: 43m 3s\tremaining: 6m 5s\n",
            "876:\tlearn: 0.9800692\ttotal: 43m 5s\tremaining: 6m 2s\n",
            "877:\tlearn: 0.9799752\ttotal: 43m 8s\tremaining: 5m 59s\n",
            "878:\tlearn: 0.9798868\ttotal: 43m 11s\tremaining: 5m 56s\n",
            "879:\tlearn: 0.9797946\ttotal: 43m 13s\tremaining: 5m 53s\n",
            "880:\tlearn: 0.9797171\ttotal: 43m 16s\tremaining: 5m 50s\n",
            "881:\tlearn: 0.9796726\ttotal: 43m 19s\tremaining: 5m 47s\n",
            "882:\tlearn: 0.9796488\ttotal: 43m 21s\tremaining: 5m 44s\n",
            "883:\tlearn: 0.9795802\ttotal: 43m 24s\tremaining: 5m 41s\n",
            "884:\tlearn: 0.9794957\ttotal: 43m 27s\tremaining: 5m 38s\n",
            "885:\tlearn: 0.9793861\ttotal: 43m 29s\tremaining: 5m 35s\n",
            "886:\tlearn: 0.9793431\ttotal: 43m 32s\tremaining: 5m 32s\n",
            "887:\tlearn: 0.9793079\ttotal: 43m 35s\tremaining: 5m 29s\n",
            "888:\tlearn: 0.9792659\ttotal: 43m 37s\tremaining: 5m 26s\n",
            "889:\tlearn: 0.9792250\ttotal: 43m 40s\tremaining: 5m 23s\n",
            "890:\tlearn: 0.9791723\ttotal: 43m 43s\tremaining: 5m 20s\n",
            "891:\tlearn: 0.9791032\ttotal: 43m 45s\tremaining: 5m 17s\n",
            "892:\tlearn: 0.9790606\ttotal: 43m 48s\tremaining: 5m 14s\n",
            "893:\tlearn: 0.9789974\ttotal: 43m 51s\tremaining: 5m 11s\n",
            "894:\tlearn: 0.9787268\ttotal: 43m 54s\tremaining: 5m 9s\n",
            "895:\tlearn: 0.9786706\ttotal: 43m 56s\tremaining: 5m 6s\n",
            "896:\tlearn: 0.9785850\ttotal: 43m 59s\tremaining: 5m 3s\n",
            "897:\tlearn: 0.9785164\ttotal: 44m 2s\tremaining: 5m\n",
            "898:\tlearn: 0.9784669\ttotal: 44m 5s\tremaining: 4m 57s\n",
            "899:\tlearn: 0.9783946\ttotal: 44m 8s\tremaining: 4m 54s\n",
            "900:\tlearn: 0.9783284\ttotal: 44m 10s\tremaining: 4m 51s\n",
            "901:\tlearn: 0.9782159\ttotal: 44m 13s\tremaining: 4m 48s\n",
            "902:\tlearn: 0.9781672\ttotal: 44m 16s\tremaining: 4m 45s\n",
            "903:\tlearn: 0.9780467\ttotal: 44m 19s\tremaining: 4m 42s\n",
            "904:\tlearn: 0.9779686\ttotal: 44m 22s\tremaining: 4m 39s\n",
            "905:\tlearn: 0.9779245\ttotal: 44m 25s\tremaining: 4m 36s\n",
            "906:\tlearn: 0.9778735\ttotal: 44m 27s\tremaining: 4m 33s\n",
            "907:\tlearn: 0.9778081\ttotal: 44m 30s\tremaining: 4m 30s\n",
            "908:\tlearn: 0.9777314\ttotal: 44m 33s\tremaining: 4m 27s\n",
            "909:\tlearn: 0.9776079\ttotal: 44m 36s\tremaining: 4m 24s\n",
            "910:\tlearn: 0.9775772\ttotal: 44m 39s\tremaining: 4m 21s\n",
            "911:\tlearn: 0.9775241\ttotal: 44m 42s\tremaining: 4m 18s\n",
            "912:\tlearn: 0.9774468\ttotal: 44m 45s\tremaining: 4m 15s\n",
            "913:\tlearn: 0.9774327\ttotal: 44m 49s\tremaining: 4m 13s\n",
            "914:\tlearn: 0.9773706\ttotal: 44m 52s\tremaining: 4m 10s\n",
            "915:\tlearn: 0.9773403\ttotal: 44m 55s\tremaining: 4m 7s\n",
            "916:\tlearn: 0.9772998\ttotal: 44m 58s\tremaining: 4m 4s\n",
            "917:\tlearn: 0.9772422\ttotal: 45m 1s\tremaining: 4m 1s\n",
            "918:\tlearn: 0.9771522\ttotal: 45m 4s\tremaining: 3m 58s\n",
            "919:\tlearn: 0.9770933\ttotal: 45m 7s\tremaining: 3m 55s\n",
            "920:\tlearn: 0.9770061\ttotal: 45m 10s\tremaining: 3m 52s\n",
            "921:\tlearn: 0.9769816\ttotal: 45m 13s\tremaining: 3m 49s\n",
            "922:\tlearn: 0.9769533\ttotal: 45m 16s\tremaining: 3m 46s\n",
            "923:\tlearn: 0.9768131\ttotal: 45m 18s\tremaining: 3m 43s\n",
            "924:\tlearn: 0.9767029\ttotal: 45m 21s\tremaining: 3m 40s\n",
            "925:\tlearn: 0.9766356\ttotal: 45m 24s\tremaining: 3m 37s\n",
            "926:\tlearn: 0.9765544\ttotal: 45m 27s\tremaining: 3m 34s\n",
            "927:\tlearn: 0.9765256\ttotal: 45m 30s\tremaining: 3m 31s\n",
            "928:\tlearn: 0.9764207\ttotal: 45m 33s\tremaining: 3m 28s\n",
            "929:\tlearn: 0.9762984\ttotal: 45m 35s\tremaining: 3m 25s\n",
            "930:\tlearn: 0.9762726\ttotal: 45m 38s\tremaining: 3m 22s\n",
            "931:\tlearn: 0.9762427\ttotal: 45m 41s\tremaining: 3m 20s\n",
            "932:\tlearn: 0.9761860\ttotal: 45m 44s\tremaining: 3m 17s\n",
            "933:\tlearn: 0.9761409\ttotal: 45m 47s\tremaining: 3m 14s\n",
            "934:\tlearn: 0.9760698\ttotal: 45m 49s\tremaining: 3m 11s\n",
            "935:\tlearn: 0.9760255\ttotal: 45m 52s\tremaining: 3m 8s\n",
            "936:\tlearn: 0.9759375\ttotal: 45m 55s\tremaining: 3m 5s\n",
            "937:\tlearn: 0.9758867\ttotal: 45m 58s\tremaining: 3m 2s\n",
            "938:\tlearn: 0.9758679\ttotal: 46m 1s\tremaining: 2m 59s\n",
            "939:\tlearn: 0.9758043\ttotal: 46m 4s\tremaining: 2m 56s\n",
            "940:\tlearn: 0.9757391\ttotal: 46m 6s\tremaining: 2m 53s\n",
            "941:\tlearn: 0.9756297\ttotal: 46m 9s\tremaining: 2m 50s\n",
            "942:\tlearn: 0.9755743\ttotal: 46m 12s\tremaining: 2m 47s\n",
            "943:\tlearn: 0.9755504\ttotal: 46m 15s\tremaining: 2m 44s\n",
            "944:\tlearn: 0.9754586\ttotal: 46m 18s\tremaining: 2m 41s\n",
            "945:\tlearn: 0.9753870\ttotal: 46m 21s\tremaining: 2m 38s\n",
            "946:\tlearn: 0.9753410\ttotal: 46m 23s\tremaining: 2m 35s\n",
            "947:\tlearn: 0.9752529\ttotal: 46m 26s\tremaining: 2m 32s\n",
            "948:\tlearn: 0.9751849\ttotal: 46m 29s\tremaining: 2m 29s\n",
            "949:\tlearn: 0.9751068\ttotal: 46m 32s\tremaining: 2m 26s\n",
            "950:\tlearn: 0.9749945\ttotal: 46m 35s\tremaining: 2m 24s\n",
            "951:\tlearn: 0.9749206\ttotal: 46m 38s\tremaining: 2m 21s\n",
            "952:\tlearn: 0.9748541\ttotal: 46m 41s\tremaining: 2m 18s\n",
            "953:\tlearn: 0.9747898\ttotal: 46m 44s\tremaining: 2m 15s\n",
            "954:\tlearn: 0.9747255\ttotal: 46m 47s\tremaining: 2m 12s\n",
            "955:\tlearn: 0.9746182\ttotal: 46m 50s\tremaining: 2m 9s\n",
            "956:\tlearn: 0.9745137\ttotal: 46m 52s\tremaining: 2m 6s\n",
            "957:\tlearn: 0.9744302\ttotal: 46m 55s\tremaining: 2m 3s\n",
            "958:\tlearn: 0.9743590\ttotal: 46m 58s\tremaining: 2m\n",
            "959:\tlearn: 0.9743385\ttotal: 47m 1s\tremaining: 1m 57s\n",
            "960:\tlearn: 0.9742526\ttotal: 47m 4s\tremaining: 1m 54s\n",
            "961:\tlearn: 0.9741722\ttotal: 47m 7s\tremaining: 1m 51s\n",
            "962:\tlearn: 0.9741113\ttotal: 47m 9s\tremaining: 1m 48s\n",
            "963:\tlearn: 0.9740958\ttotal: 47m 12s\tremaining: 1m 45s\n",
            "964:\tlearn: 0.9740434\ttotal: 47m 15s\tremaining: 1m 42s\n",
            "965:\tlearn: 0.9740219\ttotal: 47m 18s\tremaining: 1m 39s\n",
            "966:\tlearn: 0.9739952\ttotal: 47m 20s\tremaining: 1m 36s\n",
            "967:\tlearn: 0.9739870\ttotal: 47m 23s\tremaining: 1m 34s\n",
            "968:\tlearn: 0.9739138\ttotal: 47m 26s\tremaining: 1m 31s\n",
            "969:\tlearn: 0.9738274\ttotal: 47m 29s\tremaining: 1m 28s\n",
            "970:\tlearn: 0.9738142\ttotal: 47m 32s\tremaining: 1m 25s\n",
            "971:\tlearn: 0.9737370\ttotal: 47m 34s\tremaining: 1m 22s\n",
            "972:\tlearn: 0.9736443\ttotal: 47m 37s\tremaining: 1m 19s\n",
            "973:\tlearn: 0.9735514\ttotal: 47m 40s\tremaining: 1m 16s\n",
            "974:\tlearn: 0.9734917\ttotal: 47m 43s\tremaining: 1m 13s\n",
            "975:\tlearn: 0.9734339\ttotal: 47m 46s\tremaining: 1m 10s\n",
            "976:\tlearn: 0.9733248\ttotal: 47m 49s\tremaining: 1m 7s\n",
            "977:\tlearn: 0.9732459\ttotal: 47m 52s\tremaining: 1m 4s\n",
            "978:\tlearn: 0.9732378\ttotal: 47m 55s\tremaining: 1m 1s\n",
            "979:\tlearn: 0.9732205\ttotal: 47m 58s\tremaining: 58.7s\n",
            "980:\tlearn: 0.9731867\ttotal: 48m 1s\tremaining: 55.8s\n",
            "981:\tlearn: 0.9731741\ttotal: 48m 4s\tremaining: 52.9s\n",
            "982:\tlearn: 0.9731515\ttotal: 48m 7s\tremaining: 49.9s\n",
            "983:\tlearn: 0.9730882\ttotal: 48m 10s\tremaining: 47s\n",
            "984:\tlearn: 0.9730317\ttotal: 48m 12s\tremaining: 44.1s\n",
            "985:\tlearn: 0.9729950\ttotal: 48m 15s\tremaining: 41.1s\n",
            "986:\tlearn: 0.9729625\ttotal: 48m 19s\tremaining: 38.2s\n",
            "987:\tlearn: 0.9729132\ttotal: 48m 22s\tremaining: 35.2s\n",
            "988:\tlearn: 0.9728009\ttotal: 48m 25s\tremaining: 32.3s\n",
            "989:\tlearn: 0.9727794\ttotal: 48m 27s\tremaining: 29.4s\n",
            "990:\tlearn: 0.9727660\ttotal: 48m 30s\tremaining: 26.4s\n",
            "991:\tlearn: 0.9727202\ttotal: 48m 33s\tremaining: 23.5s\n",
            "992:\tlearn: 0.9726888\ttotal: 48m 36s\tremaining: 20.6s\n",
            "993:\tlearn: 0.9726292\ttotal: 48m 39s\tremaining: 17.6s\n",
            "994:\tlearn: 0.9725919\ttotal: 48m 42s\tremaining: 14.7s\n",
            "995:\tlearn: 0.9725189\ttotal: 48m 45s\tremaining: 11.7s\n",
            "996:\tlearn: 0.9724410\ttotal: 48m 48s\tremaining: 8.81s\n",
            "997:\tlearn: 0.9723216\ttotal: 48m 51s\tremaining: 5.88s\n",
            "998:\tlearn: 0.9722309\ttotal: 48m 54s\tremaining: 2.94s\n",
            "999:\tlearn: 0.9721939\ttotal: 48m 58s\tremaining: 0us\n",
            "accuracy %s 0.6216305062458909\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Anxiety       0.75      0.73      0.74      4041\n",
            "          BPD       0.73      0.75      0.74      4138\n",
            "      bipolar       0.70      0.50      0.59      4092\n",
            "   depression       0.58      0.53      0.55      4125\n",
            "mentalillness       0.53      0.42      0.47      3972\n",
            "schizophrenia       0.50      0.79      0.61      3968\n",
            "\n",
            "     accuracy                           0.62     24336\n",
            "    macro avg       0.63      0.62      0.62     24336\n",
            " weighted avg       0.63      0.62      0.62     24336\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pipe_cat = Pipeline([\n",
        "           ('vect', TfidfVectorizer(max_features=5000,ngram_range=(1,2))),\n",
        "           ('clf', CatBoostClassifier()),\n",
        "])\n",
        "pipe_cat.fit(X_train, y_train)\n",
        "y_pred = pipe_cat.predict(X_test)\n",
        "predicted_prob = pipe_cat.predict_proba(X_test)\n",
        "\n",
        "print('accuracy %s',  accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy %s 0.6265614727153189\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Anxiety       0.73      0.75      0.74      4041\n",
            "          BPD       0.75      0.77      0.76      4138\n",
            "      bipolar       0.72      0.51      0.59      4092\n",
            "   depression       0.61      0.50      0.55      4125\n",
            "mentalillness       0.52      0.45      0.48      3972\n",
            "schizophrenia       0.50      0.79      0.61      3968\n",
            "\n",
            "     accuracy                           0.63     24336\n",
            "    macro avg       0.64      0.63      0.62     24336\n",
            " weighted avg       0.64      0.63      0.62     24336\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X = df_equals['selftext']\n",
        "y = df_equals[\"subreddit\"].apply(perform_lemmatize)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "\n",
        "\n",
        "pipe_log = Pipeline([\n",
        "           ('vect', TfidfVectorizer(max_features= 5000,ngram_range=(1,1))),\n",
        "           ('clf', LogisticRegression(C=1.0,penalty='l2',random_state=42,n_jobs=-1)),\n",
        "])\n",
        "pipe_log.fit(X_train, y_train)\n",
        "y_pred = pipe_log.predict(X_test)\n",
        "predicted_prob = pipe_log.predict_proba(X_test)\n",
        "\n",
        "print('accuracy %s',  accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>selftext</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>over_18</th>\n",
              "      <th>subreddit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>219059</th>\n",
              "      <td>bpddepression self careneglectbasic care</td>\n",
              "      <td>hey yall today wanted make post basic care one...</td>\n",
              "      <td>1.508618e+09</td>\n",
              "      <td>False</td>\n",
              "      <td>BPD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219060</th>\n",
              "      <td>fp decided ’ better part ways</td>\n",
              "      <td>knew coming actually happened feel like shit y...</td>\n",
              "      <td>1.508617e+09</td>\n",
              "      <td>False</td>\n",
              "      <td>BPD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219061</th>\n",
              "      <td>someone asks</td>\n",
              "      <td>feeling today lately get flashback good things...</td>\n",
              "      <td>1.508612e+09</td>\n",
              "      <td>False</td>\n",
              "      <td>BPD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219062</th>\n",
              "      <td>work</td>\n",
              "      <td>yet ive found position jobless job really like...</td>\n",
              "      <td>1.508612e+09</td>\n",
              "      <td>False</td>\n",
              "      <td>BPD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219063</th>\n",
              "      <td>friends go something without</td>\n",
              "      <td>find snapchat wouldnt anyway probably thought ...</td>\n",
              "      <td>1.508609e+09</td>\n",
              "      <td>False</td>\n",
              "      <td>BPD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701779</th>\n",
              "      <td>really need talk therapist</td>\n",
              "      <td>cant afford real session 11 pm somebody please...</td>\n",
              "      <td>1.415332e+09</td>\n",
              "      <td>False</td>\n",
              "      <td>mentalillness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701781</th>\n",
              "      <td>pica</td>\n",
              "      <td>hello im taking steps get rid pica ive picaing...</td>\n",
              "      <td>1.414897e+09</td>\n",
              "      <td>False</td>\n",
              "      <td>mentalillness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701782</th>\n",
              "      <td>go get help someone mentally ill psyche wards ...</td>\n",
              "      <td>someone war veteran know mentally ill wont see...</td>\n",
              "      <td>1.396298e+09</td>\n",
              "      <td>False</td>\n",
              "      <td>mentalillness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701783</th>\n",
              "      <td>rooster illusion</td>\n",
              "      <td>ama</td>\n",
              "      <td>1.344640e+09</td>\n",
              "      <td>False</td>\n",
              "      <td>mentalillness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701786</th>\n",
              "      <td>crazy motherfucker</td>\n",
              "      <td>lot random impluses crazy shit like right want...</td>\n",
              "      <td>1.321507e+09</td>\n",
              "      <td>False</td>\n",
              "      <td>mentalillness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>121680 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    title  \\\n",
              "219059           bpddepression self careneglectbasic care   \n",
              "219060                      fp decided ’ better part ways   \n",
              "219061                                       someone asks   \n",
              "219062                                               work   \n",
              "219063                       friends go something without   \n",
              "...                                                   ...   \n",
              "701779                         really need talk therapist   \n",
              "701781                                               pica   \n",
              "701782  go get help someone mentally ill psyche wards ...   \n",
              "701783                                   rooster illusion   \n",
              "701786                                 crazy motherfucker   \n",
              "\n",
              "                                                 selftext   created_utc  \\\n",
              "219059  hey yall today wanted make post basic care one...  1.508618e+09   \n",
              "219060  knew coming actually happened feel like shit y...  1.508617e+09   \n",
              "219061  feeling today lately get flashback good things...  1.508612e+09   \n",
              "219062  yet ive found position jobless job really like...  1.508612e+09   \n",
              "219063  find snapchat wouldnt anyway probably thought ...  1.508609e+09   \n",
              "...                                                   ...           ...   \n",
              "701779  cant afford real session 11 pm somebody please...  1.415332e+09   \n",
              "701781  hello im taking steps get rid pica ive picaing...  1.414897e+09   \n",
              "701782  someone war veteran know mentally ill wont see...  1.396298e+09   \n",
              "701783                                                ama  1.344640e+09   \n",
              "701786  lot random impluses crazy shit like right want...  1.321507e+09   \n",
              "\n",
              "       over_18      subreddit  \n",
              "219059   False            BPD  \n",
              "219060   False            BPD  \n",
              "219061   False            BPD  \n",
              "219062   False            BPD  \n",
              "219063   False            BPD  \n",
              "...        ...            ...  \n",
              "701779   False  mentalillness  \n",
              "701781   False  mentalillness  \n",
              "701782   False  mentalillness  \n",
              "701783   False  mentalillness  \n",
              "701786   False  mentalillness  \n",
              "\n",
              "[121680 rows x 5 columns]"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_equals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BPD              20019\n",
              "Anxiety          19651\n",
              "mentalillness    18526\n",
              "bipolar          15666\n",
              "depression       15628\n",
              "schizophrenia    11727\n",
              "Name: subreddit, dtype: int64"
            ]
          },
          "execution_count": 178,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_equals=df_equals[df_equals['selftext'] != 'removed']\n",
        "df_equals['subreddit'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_equals=category_equalization(df_equals,'subreddit')\n",
        "df_equals=df_equals.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BPD              11727\n",
              "bipolar          11727\n",
              "depression       11727\n",
              "Anxiety          11727\n",
              "schizophrenia    11727\n",
              "mentalillness    11727\n",
              "Name: subreddit, dtype: int64"
            ]
          },
          "execution_count": 182,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_equals['subreddit'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, TfidfVectorizer(max_features=5000)),\n",
              "                (&#x27;clf&#x27;, LogisticRegression(n_jobs=-1, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, TfidfVectorizer(max_features=5000)),\n",
              "                (&#x27;clf&#x27;, LogisticRegression(n_jobs=-1, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=5000)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('vect', TfidfVectorizer(max_features=5000)),\n",
              "                ('clf', LogisticRegression(n_jobs=-1, random_state=42))])"
            ]
          },
          "execution_count": 183,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = df_equals['selftext']\n",
        "y = df_equals[\"subreddit\"].apply(perform_lemmatize)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "pipe_log.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy %s 0.6629005897818517\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Anxiety       0.72      0.73      0.73      2340\n",
            "          BPD       0.72      0.76      0.74      2316\n",
            "      bipolar       0.71      0.65      0.68      2341\n",
            "   depression       0.59      0.70      0.64      2362\n",
            "mentalillness       0.53      0.44      0.48      2325\n",
            "schizophrenia       0.68      0.71      0.69      2389\n",
            "\n",
            "     accuracy                           0.66     14073\n",
            "    macro avg       0.66      0.66      0.66     14073\n",
            " weighted avg       0.66      0.66      0.66     14073\n",
            "\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = pipe_log.predict(X_test)\n",
        "predicted_prob = pipe_log.predict_proba(X_test)\n",
        "\n",
        "print('accuracy %s',  accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_pipeline = Pipeline(steps=[\n",
        "    ('vect',TfidfVectorizer(max_features= 10000,ngram_range=(1,2)))\n",
        "])\n",
        "\n",
        "num_pipeline = Pipeline(steps=[\n",
        "    \n",
        "    ('vect', TfidfVectorizer(max_features= 10000,ngram_range=(1,2)))\n",
        "])\n",
        "\n",
        "col_trans = ColumnTransformer(transformers=[\n",
        "   \n",
        "    ('num_pipeline',num_pipeline,'selftext'),\n",
        "    ('cat_pipeline',cat_pipeline,'title')\n",
        "    ],\n",
        "    \n",
        "    n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline = Pipeline(steps=[('preprocessor', col_trans), ('classifier',LogisticRegression(C=1.0,penalty='l2',random_state=42,n_jobs=-1))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_equals['selftext']=df_equals['selftext'].apply(perform_lemmatize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_equals['title']=df_equals['title'].apply(perform_lemmatize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(n_jobs=-1,\n",
              "                                   transformers=[(&#x27;num_pipeline&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;vect&#x27;,\n",
              "                                                                   TfidfVectorizer(max_features=10000,\n",
              "                                                                                   ngram_range=(1,\n",
              "                                                                                                2)))]),\n",
              "                                                  &#x27;selftext&#x27;),\n",
              "                                                 (&#x27;cat_pipeline&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;vect&#x27;,\n",
              "                                                                   TfidfVectorizer(max_features=10000,\n",
              "                                                                                   ngram_range=(1,\n",
              "                                                                                                2)))]),\n",
              "                                                  &#x27;title&#x27;)])),\n",
              "                (&#x27;classifier&#x27;, LogisticRegression(n_jobs=-1, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(n_jobs=-1,\n",
              "                                   transformers=[(&#x27;num_pipeline&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;vect&#x27;,\n",
              "                                                                   TfidfVectorizer(max_features=10000,\n",
              "                                                                                   ngram_range=(1,\n",
              "                                                                                                2)))]),\n",
              "                                                  &#x27;selftext&#x27;),\n",
              "                                                 (&#x27;cat_pipeline&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;vect&#x27;,\n",
              "                                                                   TfidfVectorizer(max_features=10000,\n",
              "                                                                                   ngram_range=(1,\n",
              "                                                                                                2)))]),\n",
              "                                                  &#x27;title&#x27;)])),\n",
              "                (&#x27;classifier&#x27;, LogisticRegression(n_jobs=-1, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(n_jobs=-1,\n",
              "                  transformers=[(&#x27;num_pipeline&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;vect&#x27;,\n",
              "                                                  TfidfVectorizer(max_features=10000,\n",
              "                                                                  ngram_range=(1,\n",
              "                                                                               2)))]),\n",
              "                                 &#x27;selftext&#x27;),\n",
              "                                (&#x27;cat_pipeline&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;vect&#x27;,\n",
              "                                                  TfidfVectorizer(max_features=10000,\n",
              "                                                                  ngram_range=(1,\n",
              "                                                                               2)))]),\n",
              "                                 &#x27;title&#x27;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num_pipeline</label><div class=\"sk-toggleable__content\"><pre>selftext</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=10000, ngram_range=(1, 2))</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat_pipeline</label><div class=\"sk-toggleable__content\"><pre>title</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=10000, ngram_range=(1, 2))</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(n_jobs=-1,\n",
              "                                   transformers=[('num_pipeline',\n",
              "                                                  Pipeline(steps=[('vect',\n",
              "                                                                   TfidfVectorizer(max_features=10000,\n",
              "                                                                                   ngram_range=(1,\n",
              "                                                                                                2)))]),\n",
              "                                                  'selftext'),\n",
              "                                                 ('cat_pipeline',\n",
              "                                                  Pipeline(steps=[('vect',\n",
              "                                                                   TfidfVectorizer(max_features=10000,\n",
              "                                                                                   ngram_range=(1,\n",
              "                                                                                                2)))]),\n",
              "                                                  'title')])),\n",
              "                ('classifier', LogisticRegression(n_jobs=-1, random_state=42))])"
            ]
          },
          "execution_count": 223,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = df_equals[['selftext','title']]\n",
        "y = df_equals[\"subreddit\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy %s 0.6965110495274639\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Anxiety       0.77      0.76      0.77      2340\n",
            "          BPD       0.75      0.78      0.77      2316\n",
            "      bipolar       0.75      0.69      0.72      2341\n",
            "   depression       0.61      0.72      0.66      2362\n",
            "mentalillness       0.55      0.49      0.52      2325\n",
            "schizophrenia       0.74      0.73      0.74      2389\n",
            "\n",
            "     accuracy                           0.70     14073\n",
            "    macro avg       0.70      0.70      0.70     14073\n",
            " weighted avg       0.70      0.70      0.70     14073\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = pipeline.predict(X_test)\n",
        "predicted_prob = pipeline.predict_proba(X_test)\n",
        "\n",
        "print('accuracy %s',  accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "548cd44066715416e426fef964f3b8dd211c8b15dd1cb37f284d034890ee9085"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
