{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('mental_disorders_reddit.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "df=df.dropna(how='any')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: joblib in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk) (0.4.4)\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_lowercase(text):\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "def remove_url(text):\n",
        "    re_url = re.compile('https?://\\S+|www\\.\\S+')\n",
        "    return re_url.sub('', text)\n",
        "\n",
        "exclude = string.punctuation\n",
        "def remove_punc(text):\n",
        "    return text.translate(str.maketrans('', '', exclude))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    new_list = []\n",
        "    words = word_tokenize(text)\n",
        "    stopwrds = stopwords.words('english')\n",
        "    for word in words:\n",
        "        if word not in stopwrds:\n",
        "            new_list.append(word)\n",
        "    return ' '.join(new_list)\n",
        "\n",
        "\n",
        "def perform_stemming(text):\n",
        "    stemmer = PorterStemmer()\n",
        "    new_list = []\n",
        "    words = word_tokenize(text)\n",
        "    for word in words:\n",
        "        new_list.append(stemmer.stem(word))\n",
        "\n",
        "    return \" \".join(new_list)\n",
        "\n",
        "\n",
        "def perform_lemmatize(text):\n",
        "    lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "    new_list = []\n",
        "    words = word_tokenize(text)\n",
        "    for word in words:\n",
        "        new_list.append(lem.lemmatize(word))\n",
        "\n",
        "    return \" \".join(new_list)\n",
        "\n",
        "\n",
        "def category_equalization(data_df,col):# функция для баланса значений категорий в таргет \n",
        "    for value in list(data_df[col].unique()):\n",
        "        \n",
        "        num_rows_to_remove=data_df[col].value_counts()[value]-data_df[col].value_counts()['schizophrenia']#надо поменять на мимнимальное значение в value_counts \n",
        "        \n",
        "        rows_with_value = data_df[data_df[col] == value]\n",
        "\n",
        "        data_df = data_df[~data_df.isin(rows_with_value.head(num_rows_to_remove))]\n",
        "    return data_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_equals=category_equalization(df,\"subreddit\")\n",
        "df_equals=df_equals.dropna()\n",
        "df_equals=df_equals[df_equals['selftext'] != 'removed']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_equals['selftext']=df_equals['selftext'].apply(remove_url)\n",
        "df_equals['selftext']=df_equals['selftext'].apply(remove_punc)\n",
        "df_equals['selftext']=df_equals['selftext'].apply(convert_lowercase)\n",
        "df_equals['selftext']=df_equals['selftext'].apply(remove_stopwords)\n",
        "df_equals['selftext']=df_equals['selftext'].apply(perform_lemmatize)\n",
        "\n",
        "df_equals['title']=df_equals['title'].apply(remove_url)\n",
        "df_equals['title']=df_equals['title'].apply(remove_punc)\n",
        "df_equals['title']=df_equals['title'].apply(convert_lowercase)\n",
        "df_equals['title']=df_equals['title'].apply(remove_stopwords)\n",
        "df_equals['title']=df_equals['title'].apply(perform_lemmatize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BPD              20280\n",
              "bipolar          20280\n",
              "depression       20280\n",
              "Anxiety          20280\n",
              "schizophrenia    20280\n",
              "mentalillness    20280\n",
              "Name: subreddit, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_equals[\"subreddit\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_equals = df_equals[(df_equals['selftext'].str.len() > 10)]\n",
        "df_equals=category_equalization(df_equals,'subreddit').dropna(how='any')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BPD              11374\n",
              "bipolar          11374\n",
              "depression       11374\n",
              "Anxiety          11374\n",
              "schizophrenia    11374\n",
              "mentalillness    11374\n",
              "Name: subreddit, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_equals[\"subreddit\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "import numpy as np"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "РАБОТА С ОДНИМ ПРИЗНАКОМ 'selftext'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "y = df_equals['subreddit']\n",
        "X = df_equals['selftext']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 72 candidates, totalling 144 fits\n",
            "{'clf__C': 1.0, 'clf__penalty': 'l2', 'vect__max_features': 50000, 'vect__ngram_range': (1, 3)}\n",
            "0.6580456134900076\n"
          ]
        }
      ],
      "source": [
        "\n",
        "pipe_logreg = Pipeline([\n",
        "           ('vect', TfidfVectorizer()),\n",
        "           ('clf', LogisticRegression(n_jobs=-1)),\n",
        "])\n",
        "parameters = [{\n",
        "    'vect__max_features':[5000, 10000, 50000],\n",
        "     'vect__ngram_range': [(1,1), (1,2), (1,3)],\n",
        "    'clf__penalty': ('l1','l2'),\n",
        "    'clf__C': (10, 1.0, 0.1, 0.01)\n",
        "}]\n",
        "\n",
        "grid_search = GridSearchCV(pipe_logreg, parameters,verbose=5,n_jobs=-1,cv=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy %s 0.6746281778884899\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Anxiety       0.75      0.76      0.75      2307\n",
            "          BPD       0.74      0.74      0.74      2244\n",
            "      bipolar       0.72      0.67      0.69      2239\n",
            "   depression       0.58      0.71      0.64      2276\n",
            "mentalillness       0.55      0.46      0.50      2281\n",
            "schizophrenia       0.71      0.71      0.71      2302\n",
            "\n",
            "     accuracy                           0.67     13649\n",
            "    macro avg       0.68      0.67      0.67     13649\n",
            " weighted avg       0.67      0.67      0.67     13649\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "pipe_log = Pipeline([\n",
        "           ('vect', TfidfVectorizer(max_features= 50000,ngram_range=(1,3))),\n",
        "           ('clf', LogisticRegression(C=1.0,penalty='l2',random_state=42,n_jobs=-1)),\n",
        "])\n",
        "pipe_log.fit(X_train, y_train)\n",
        "y_pred = pipe_log.predict(X_test)\n",
        "predicted_prob = pipe_log.predict_proba(X_test)\n",
        "\n",
        "print('accuracy %s',  accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rate set to 0.146779\n",
            "0:\tlearn: 1.6484492\ttotal: 427ms\tremaining: 7m 6s\n",
            "150:\tlearn: 0.9842761\ttotal: 43.2s\tremaining: 4m 2s\n",
            "300:\tlearn: 0.9097480\ttotal: 1m 22s\tremaining: 3m 10s\n",
            "450:\tlearn: 0.8769443\ttotal: 1m 57s\tremaining: 2m 22s\n",
            "600:\tlearn: 0.8563338\ttotal: 2m 31s\tremaining: 1m 40s\n",
            "750:\tlearn: 0.8398740\ttotal: 3m 4s\tremaining: 1m 1s\n",
            "900:\tlearn: 0.8266160\ttotal: 3m 38s\tremaining: 24s\n",
            "999:\tlearn: 0.8188528\ttotal: 3m 59s\tremaining: 0us\n",
            "accuracy %s 0.6670818374972526\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Anxiety       0.76      0.74      0.75      2307\n",
            "          BPD       0.75      0.73      0.74      2244\n",
            "      bipolar       0.75      0.66      0.70      2239\n",
            "   depression       0.57      0.70      0.63      2276\n",
            "mentalillness       0.56      0.44      0.49      2281\n",
            "schizophrenia       0.64      0.74      0.69      2302\n",
            "\n",
            "     accuracy                           0.67     13649\n",
            "    macro avg       0.67      0.67      0.67     13649\n",
            " weighted avg       0.67      0.67      0.67     13649\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pipe_cat = Pipeline([\n",
        "           ('vect', TfidfVectorizer(max_features=10000,ngram_range=(1,3))),\n",
        "           ('clf', CatBoostClassifier(task_type = 'GPU', verbose=150)),\n",
        "])\n",
        "pipe_cat.fit(X_train, y_train)\n",
        "y_pred = pipe_cat.predict(X_test)\n",
        "predicted_prob = pipe_cat.predict_proba(X_test)\n",
        "\n",
        "print('accuracy %s',  accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightgbm import LGBMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy %s 0.6767528756685471\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Anxiety       0.73      0.75      0.74      2307\n",
            "          BPD       0.77      0.75      0.76      2244\n",
            "      bipolar       0.72      0.67      0.70      2239\n",
            "   depression       0.59      0.69      0.63      2276\n",
            "mentalillness       0.54      0.48      0.51      2281\n",
            "schizophrenia       0.71      0.72      0.71      2302\n",
            "\n",
            "     accuracy                           0.68     13649\n",
            "    macro avg       0.68      0.68      0.68     13649\n",
            " weighted avg       0.68      0.68      0.68     13649\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pipe_cat = Pipeline([\n",
        "           ('vect', TfidfVectorizer(max_features=10000,ngram_range=(1,3))),\n",
        "           ('clf', LGBMClassifier(boosting_type='gbdt', num_leaves=100, max_depth=-1, learning_rate=0.1, n_estimators=200,n_jobs=-1)),\n",
        "])\n",
        "pipe_cat.fit(X_train, y_train)\n",
        "y_pred = pipe_cat.predict(X_test)\n",
        "predicted_prob = pipe_cat.predict_proba(X_test)\n",
        "\n",
        "print('accuracy %s',  accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "РАБОТА С ДВУМЯ ПРИЗНАКОМ 'selftext' и 'title'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "y = df_equals['subreddit']\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "X = df_equals[['title','selftext']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import FeatureUnion\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocessor1 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('tfidf1', TfidfVectorizer(), 'title')\n",
        "    ])\n",
        "\n",
        "preprocessor2 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('tfidf2', TfidfVectorizer(), 'selftext')\n",
        "    ])\n",
        "\n",
        "preprocessor = FeatureUnion([\n",
        "    ('preprocessor1', preprocessor1),\n",
        "    ('preprocessor2', preprocessor2)\n",
        "])\n",
        "\n",
        "\n",
        "model = xgb.XGBClassifier()\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', model)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy %s 0.6918431685981973\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.76      0.77      3797\n",
            "           1       0.78      0.74      0.76      3712\n",
            "           2       0.78      0.70      0.73      3711\n",
            "           3       0.59      0.73      0.65      3786\n",
            "           4       0.56      0.47      0.51      3758\n",
            "           5       0.69      0.76      0.72      3757\n",
            "\n",
            "    accuracy                           0.69     22521\n",
            "   macro avg       0.70      0.69      0.69     22521\n",
            "weighted avg       0.69      0.69      0.69     22521\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = xgb.XGBClassifier(max_depth=100,n_jods=-1)\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_test)\n",
        "predicted_prob = pipeline.predict_proba(X_test)\n",
        "print('accuracy %s',  accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy %s 0.6918431685981973\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.76      0.77      3797\n",
            "           1       0.78      0.74      0.76      3712\n",
            "           2       0.78      0.70      0.73      3711\n",
            "           3       0.59      0.73      0.65      3786\n",
            "           4       0.56      0.47      0.51      3758\n",
            "           5       0.69      0.76      0.72      3757\n",
            "\n",
            "    accuracy                           0.69     22521\n",
            "   macro avg       0.70      0.69      0.69     22521\n",
            "weighted avg       0.69      0.69      0.69     22521\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model=CatBoostClassifier(task_type = 'GPU', verbose=150)\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_test)\n",
        "predicted_prob = pipeline.predict_proba(X_test)\n",
        "print('accuracy %s',  accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy %s 0.6918431685981973\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.76      0.77      3797\n",
            "           1       0.78      0.74      0.76      3712\n",
            "           2       0.78      0.70      0.73      3711\n",
            "           3       0.59      0.73      0.65      3786\n",
            "           4       0.56      0.47      0.51      3758\n",
            "           5       0.69      0.76      0.72      3757\n",
            "\n",
            "    accuracy                           0.69     22521\n",
            "   macro avg       0.70      0.69      0.69     22521\n",
            "weighted avg       0.69      0.69      0.69     22521\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "model=MLPClassifier(hidden_layer_sizes=200,activation='tanh',solver='sgd')\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_test)\n",
        "predicted_prob = pipeline.predict_proba(X_test)\n",
        "print('accuracy %s',  accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tfidf_param_grid = {\n",
        "    'preprocessor__preprocessor1__tfidf1__max_features': [1000,5000,10000],\n",
        "    'preprocessor__preprocessor1__tfidf1__ngram_range': [(1, 1), (1, 3)],\n",
        "    'preprocessor__preprocessor2__tfidf2__max_features': [2500, 1000,5000],\n",
        "    'preprocessor__preprocessor2__tfidf2__ngram_range': [(1, 1), (1, 3)],\n",
        "}\n",
        "\n",
        "# Define the hyperparameters for XGBoost\n",
        "xgb_param_grid = {\n",
        "    'model__learning_rate': [0.05],\n",
        "    'model__max_depth': [3, 5, 10, 20],\n",
        "    'model__n_estimators': [250,500,1000]\n",
        "}\n",
        "\n",
        "param_grid = {**tfidf_param_grid, **xgb_param_grid}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 432 candidates, totalling 864 fits\n"
          ]
        }
      ],
      "source": [
        "model = xgb.XGBClassifier()\n",
        "grid_search = GridSearchCV(pipeline, param_grid, verbose=5, n_jobs=-1, cv=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.26.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.23.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: colorama in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.12)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bodya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2022.9.24)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = df_equals['subreddit']\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "X = df_equals[['selftext','subreddit']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>selftext</th>\n",
              "      <th>subreddit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>226438</th>\n",
              "      <td>one persistent difficult symptom bpd impulsive...</td>\n",
              "      <td>BPD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226439</th>\n",
              "      <td>ive started dbt programme ive taking medicatio...</td>\n",
              "      <td>BPD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226440</th>\n",
              "      <td>trapped couch dissociating something want get ...</td>\n",
              "      <td>BPD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226441</th>\n",
              "      <td>upside bpd terminal</td>\n",
              "      <td>BPD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226442</th>\n",
              "      <td>give example let try make light make humorous ...</td>\n",
              "      <td>BPD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701778</th>\n",
              "      <td>pattern loosely related random word sentence t...</td>\n",
              "      <td>mentalillness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701779</th>\n",
              "      <td>cant afford real session 11 pm somebody please...</td>\n",
              "      <td>mentalillness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701781</th>\n",
              "      <td>hello im taking step get rid pica ive picaing ...</td>\n",
              "      <td>mentalillness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701782</th>\n",
              "      <td>someone war veteran know mentally ill wont see...</td>\n",
              "      <td>mentalillness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701786</th>\n",
              "      <td>lot random impluses crazy shit like right want...</td>\n",
              "      <td>mentalillness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>68244 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 selftext      subreddit\n",
              "226438  one persistent difficult symptom bpd impulsive...            BPD\n",
              "226439  ive started dbt programme ive taking medicatio...            BPD\n",
              "226440  trapped couch dissociating something want get ...            BPD\n",
              "226441                                upside bpd terminal            BPD\n",
              "226442  give example let try make light make humorous ...            BPD\n",
              "...                                                   ...            ...\n",
              "701778  pattern loosely related random word sentence t...  mentalillness\n",
              "701779  cant afford real session 11 pm somebody please...  mentalillness\n",
              "701781  hello im taking step get rid pica ive picaing ...  mentalillness\n",
              "701782  someone war veteran know mentally ill wont see...  mentalillness\n",
              "701786  lot random impluses crazy shit like right want...  mentalillness\n",
              "\n",
              "[68244 rows x 2 columns]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "548cd44066715416e426fef964f3b8dd211c8b15dd1cb37f284d034890ee9085"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
